{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8ad028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "import visualkeras\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from tensorflow.keras.applications import mobilenet_v3, efficientnet\n",
    "import itertools \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import keras_cv\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers, layers, models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint \n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 1. å»ºç«‹æ¨¡å‹çš„å‡½å¼ (æœ€çµ‚ç©©å¥ç‰ˆï¼šç¹é Keras 3 çš„ input_tensor Bug)\n",
    "def build_model(model_name, learning_rate, dropout_rate1, dropout_rate2, dense_units, trainable_layers, num_classes, \n",
    "                freeze_base_model=False, loss_function='categorical_crossentropy'):\n",
    "    \"\"\"\n",
    "    æ ¹æ“šå‚³å…¥çš„è¶…åƒæ•¸å»ºç«‹ä¸¦ç·¨è­¯æŒ‡å®šçš„ Keras æ¨¡å‹ã€‚\n",
    "    *** ä¿®æ­£ï¼šæ”¹è®Šæ¨¡å‹æ§‹å»ºæ–¹å¼ï¼Œä»¥é¿é–‹ Keras 3 åœ¨ä½¿ç”¨ input_tensor æ™‚çš„ shape inference bug ***\n",
    "    \"\"\"\n",
    "    input_shape = (224, 224, 3) \n",
    "    \n",
    "    # --- æ­¥é©Ÿ 1ï¼šåƒä¹‹å‰ä¸€æ¨£ï¼Œå®šç¾©è¼¸å…¥å’Œæ•¸æ“šå¢å¼·å±¤ ---\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    \n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomRotation(0.15),\n",
    "            layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "            layers.RandomErasing(scale=(0.02, 0.1), value_range=[0, 255]),\n",
    "        ],\n",
    "        name=\"data_augmentation\",\n",
    "    )\n",
    "\n",
    "    # --- æ­¥é©Ÿ 2ï¼šé—œéµä¿®æ”¹ - å…ˆç¨ç«‹å‰µå»ºåŸºç¤æ¨¡å‹ï¼Œä¸å‚³å…¥ input_tensor ---\n",
    "    if model_name == 'MobileNetV3-Large':\n",
    "        # æ³¨æ„ï¼šæˆ‘å€‘ä¸å†ä½¿ç”¨ input_tensor åƒæ•¸\n",
    "        base_model = keras.applications.MobileNetV3Large(\n",
    "            input_shape=input_shape, include_top=False, weights='imagenet'\n",
    "        )\n",
    "    elif model_name == 'EfficientNet-B0':\n",
    "        # æ³¨æ„ï¼šæˆ‘å€‘ä¸å†ä½¿ç”¨ input_tensor åƒæ•¸\n",
    "        base_model = keras.applications.EfficientNetB0(\n",
    "            input_shape=input_shape, include_top=False, weights='imagenet'\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"ä¸æ”¯æ´çš„æ¨¡å‹åç¨±: {model_name}ã€‚\")\n",
    "        \n",
    "    # --- æ­¥é©Ÿ 3ï¼šè¨­å®šåŸºç¤æ¨¡å‹çš„å¯è¨“ç·´æ€§ ---\n",
    "    if freeze_base_model:\n",
    "        base_model.trainable = False\n",
    "    else:\n",
    "        base_model.trainable = True\n",
    "\n",
    "    # --- æ­¥é©Ÿ 4ï¼šæ‰‹å‹•é€£æ¥è¨ˆç®—åœ– (Graph) ---\n",
    "    # 1. åŸå§‹è¼¸å…¥ -> æ•¸æ“šå¢å¼·\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    # 2. æ•¸æ“šå¢å¼·çš„è¼¸å‡º -> åŸºç¤æ¨¡å‹\n",
    "    #    åœ¨å‡çµéšæ®µï¼ŒBNå±¤æ‡‰åœ¨æ¨æ–·æ¨¡å¼ä¸‹é‹è¡Œï¼Œæ‰€ä»¥ training=False\n",
    "    x = base_model(x, training=False) \n",
    "    \n",
    "    # 3. åŸºç¤æ¨¡å‹çš„è¼¸å‡º -> å…¨å±€æ± åŒ–å’Œåˆ†é¡é ­\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(dense_units, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate1)(x)\n",
    "    x = layers.Dense(dense_units, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate2)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # --- æ­¥é©Ÿ 5ï¼šå‰µå»ºæœ€çµ‚æ¨¡å‹ ---\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # --- æ­¥é©Ÿ 6ï¼šç·¨è­¯æ¨¡å‹ ---\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\", \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b38f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    classification_report,\n",
    "    precision_recall_curve, \n",
    "    average_precision_score, \n",
    "    roc_curve, \n",
    "    auc\n",
    ")\n",
    "from itertools import cycle\n",
    "\n",
    "# 1. MLflow è¦–è¦ºåŒ–èˆ‡æ—¥èªŒè¨˜éŒ„è¼”åŠ©å‡½å¼ (ç¶­æŒä¸è®Š)\n",
    "def plot_and_log_history(history, filename=\"history_plots.png\"):\n",
    "    \"\"\"\n",
    "    ç¹ªè£½æº–ç¢ºç‡å’Œæå¤±å‡½æ•¸çš„æ­·å²æ›²ç·šï¼Œä¸¦å°‡å…¶å„²å­˜ç‚ºåœ–ç‰‡ï¼Œæœ€å¾Œè¨˜éŒ„åˆ° MLflowã€‚\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # æº–ç¢ºç‡åœ–\n",
    "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.set_title('Accuracy over epochs')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # æå¤±å‡½æ•¸åœ–\n",
    "    ax2.plot(history.history['loss'], label='Train Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Val Loss')\n",
    "    ax2.set_title('Loss over epochs')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # å„²å­˜åœ–ç‰‡ä¸¦é—œé–‰ç¹ªåœ–\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # å°‡åœ–ç‰‡è¨˜éŒ„åˆ° MLflow\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"âœ… '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def log_confusion_matrix(y_true, y_pred, class_labels, filename=\"confusion_matrix.png\"):\n",
    "    \"\"\" ç¹ªè£½ã€å„²å­˜ä¸¦è¨˜éŒ„æ¨™æº–æ··æ·†çŸ©é™£ \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(18, 14))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap='Blues')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"âœ… '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def plot_and_log_sorted_confusion_bar(y_true, y_pred, class_labels, filename=\"sorted_correct_counts.png\"):\n",
    "    \"\"\" è¨ˆç®—ã€ç¹ªè£½ä¸¦è¨˜éŒ„ä¸€å€‹é•·æ¢åœ–ï¼Œé¡¯ç¤ºæ¯å€‹é¡åˆ¥çš„æ­£ç¢ºé æ¸¬æ•¸é‡ï¼ˆç”±é«˜åˆ°ä½æ’åºï¼‰ã€‚ \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    correct_counts = np.diag(cm)\n",
    "    \n",
    "    sorted_idx = np.argsort(correct_counts)[::-1]\n",
    "    sorted_counts = correct_counts[sorted_idx]\n",
    "    sorted_labels = np.array(class_labels)[sorted_idx]\n",
    "\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.bar(range(len(sorted_counts)), sorted_counts, color='lightgreen')\n",
    "    plt.xticks(range(len(sorted_labels)), sorted_labels, rotation=90)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Correctly Predicted Count')\n",
    "    plt.title('Correctly Predicted Count per Class (sorted)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"âœ… '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "# 2. ã€å·²ä¿®æ­£ã€‘çš„ PR å’Œ ROC æ›²ç·šå‡½å¼\n",
    "def plot_and_log_precision_recall_curves(y_true, y_probas, class_labels, filename=\"precision_recall_curves.png\"):\n",
    "    \"\"\"\n",
    "    ç‚ºæ¯å€‹é¡åˆ¥ç¹ªè£½ Precision-Recall æ›²ç·šã€‚\n",
    "    ç‰¹åˆ¥çªé¡¯è¡¨ç¾æœ€å·®çš„5å€‹é¡åˆ¥ï¼Œä¸¦å°‡åœ–è¡¨è¨˜éŒ„åˆ° MLflowã€‚\n",
    "    \"\"\"\n",
    "    # æ­¥é©Ÿ 1: è¨ˆç®—æ¯å€‹é¡åˆ¥çš„ Average Precision (AP) åˆ†æ•¸\n",
    "    class_aps = []\n",
    "    for i in range(len(class_labels)):\n",
    "        ap = average_precision_score(y_true == i, y_probas[:, i])\n",
    "        class_aps.append((ap, i))\n",
    "\n",
    "    # æ­¥é©Ÿ 2: æ ¹æ“š AP åˆ†æ•¸é€²è¡Œæ’åºï¼ˆç”±ä½åˆ°é«˜ï¼‰ï¼Œæ‰¾å‡ºæœ€å·®çš„5å€‹\n",
    "    class_aps.sort(key=lambda x: x[0])\n",
    "    worst_classes_indices = {idx for _, idx in class_aps[:5]}\n",
    "\n",
    "    # æ­¥é©Ÿ 3: ç¹ªåœ–\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal']) # ç‚ºæœ€å·®çš„5å€‹é¡åˆ¥æº–å‚™é¡è‰²\n",
    "\n",
    "    # ç¹ªè£½æ‰€æœ‰é¡åˆ¥çš„æ›²ç·š\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        precision, recall, _ = precision_recall_curve(y_true == i, y_probas[:, i])\n",
    "        ap_score = class_aps[i][0] if class_aps[i][1] == i else [s for s, j in class_aps if j == i][0] # æ‰¾åˆ°å°æ‡‰çš„AP\n",
    "\n",
    "        if i in worst_classes_indices:\n",
    "            # å¦‚æœæ˜¯è¡¨ç¾æœ€å·®çš„é¡åˆ¥ä¹‹ä¸€ï¼Œä½¿ç”¨å½©è‰²ç·šæ¢ä¸¦åŠ å…¥åœ–ä¾‹\n",
    "            plt.plot(recall, precision, lw=2.5, color=next(colors),\n",
    "                     label=f'PR curve for {class_label} (AP = {ap_score:0.3f})')\n",
    "        else:\n",
    "            # å…¶ä»–é¡åˆ¥ä½¿ç”¨ç°è‰²ç·šæ¢ï¼Œä¸åŠ å…¥åœ–ä¾‹\n",
    "            plt.plot(recall, precision, lw=1.5, color='lightgray')\n",
    "\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Multi-class Precision-Recall Curve (Highlighting 5 worst classes)\")\n",
    "    plt.legend(loc=\"best\") # é¡¯ç¤ºåœ–ä¾‹\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"âœ… '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def plot_and_log_roc_curves(y_true, y_probas, class_labels, filename=\"roc_curves.png\"):\n",
    "    \"\"\"\n",
    "    ç‚ºæ¯å€‹é¡åˆ¥ç¹ªè£½ ROC æ›²ç·šã€‚\n",
    "    ç‰¹åˆ¥çªé¡¯è¡¨ç¾æœ€å·®çš„5å€‹é¡åˆ¥ï¼Œä¸¦å°‡åœ–è¡¨è¨˜éŒ„åˆ° MLflowã€‚\n",
    "    \"\"\"\n",
    "    # æ­¥é©Ÿ 1: è¨ˆç®—æ¯å€‹é¡åˆ¥çš„ AUC åˆ†æ•¸\n",
    "    class_aucs = []\n",
    "    for i in range(len(class_labels)):\n",
    "        fpr, tpr, _ = roc_curve(y_true == i, y_probas[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        class_aucs.append((roc_auc, i))\n",
    "    \n",
    "    # æ­¥é©Ÿ 2: æ ¹æ“š AUC åˆ†æ•¸é€²è¡Œæ’åºï¼ˆç”±ä½åˆ°é«˜ï¼‰ï¼Œæ‰¾å‡ºæœ€å·®çš„5å€‹\n",
    "    class_aucs.sort(key=lambda x: x[0])\n",
    "    worst_classes_indices = {idx for _, idx in class_aucs[:5]}\n",
    "    \n",
    "    # æ­¥é©Ÿ 3: ç¹ªåœ–\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal']) # ç‚ºæœ€å·®çš„5å€‹é¡åˆ¥æº–å‚™é¡è‰²\n",
    "\n",
    "    # ç¹ªè£½æ‰€æœ‰é¡åˆ¥çš„æ›²ç·š\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        fpr, tpr, _ = roc_curve(y_true == i, y_probas[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        if i in worst_classes_indices:\n",
    "            # å¦‚æœæ˜¯è¡¨ç¾æœ€å·®çš„é¡åˆ¥ä¹‹ä¸€ï¼Œä½¿ç”¨å½©è‰²ç·šæ¢ä¸¦åŠ å…¥åœ–ä¾‹\n",
    "            plt.plot(fpr, tpr, lw=2.5, color=next(colors),\n",
    "                     label=f'ROC curve for {class_label} (AUC = {roc_auc:0.3f})')\n",
    "        else:\n",
    "            # å…¶ä»–é¡åˆ¥ä½¿ç”¨ç°è‰²ç·šæ¢ï¼Œä¸åŠ å…¥åœ–ä¾‹\n",
    "            plt.plot(fpr, tpr, lw=1.5, color='lightgray')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Guess')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Multi-class ROC Curve (Highlighting 5 worst classes)\")\n",
    "    plt.legend(loc=\"lower right\") # é¡¯ç¤ºåœ–ä¾‹\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"âœ… '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "\n",
    "# 3. æ›´æ–°å¾Œçš„ä¸»è©•ä¼°å‡½å¼\n",
    "def evaluate_and_log_all_reports(model, data_generator, class_labels):\n",
    "    \"\"\"\n",
    "    è©•ä¼°æ¨¡å‹ä¸¦è¨˜éŒ„åˆ†é¡å ±å‘Šã€æ··æ·†çŸ©é™£åŠå…¶ä»–åˆ†æåœ–ï¼ˆåŒ…æ‹¬ PR å’Œ ROC æ›²ç·šï¼‰åˆ° MLflowã€‚\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*20 + \" Starting Full Evaluation for Logging \" + \"=\"*20)\n",
    "\n",
    "    data_generator.reset()\n",
    "\n",
    "    y_probas = model.predict(data_generator, steps=len(data_generator), verbose=1)\n",
    "    y_pred = np.argmax(y_probas, axis=1)\n",
    "    y_true = data_generator.classes\n",
    "    \n",
    "    if len(y_pred) != len(y_true):\n",
    "        print(f\"âš ï¸ y_pred length {len(y_pred)} vs y_true length {len(y_true)}. This is normal if batch_size doesn't divide total samples.\")\n",
    "        y_true = y_true[:len(y_pred)]\n",
    "\n",
    "    report = classification_report(y_true, y_pred, target_names=class_labels, digits=4, zero_division=0)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    mlflow.log_text(report, \"classification_report.txt\")\n",
    "    print(\"âœ… 'classification_report.txt' has been logged to MLflow.\")\n",
    "\n",
    "    log_confusion_matrix(y_true, y_pred, class_labels)\n",
    "    plot_and_log_sorted_confusion_bar(y_true, y_pred, class_labels)\n",
    "    plot_and_log_precision_recall_curves(y_true, y_probas, class_labels)\n",
    "    plot_and_log_roc_curves(y_true, y_probas, class_labels)\n",
    "    \n",
    "    print(\"=\"*20 + \" Full Evaluation Logging Complete \" + \"=\"*20 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ad3f6",
   "metadata": {},
   "source": [
    "### å…©ç¨®æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b30e6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 2. è‡ªå‹•è¨“ç·´èˆ‡èª¿åƒçš„ä¸»å‡½å¼ (å…¨é¢å„ªåŒ–ç‰ˆ)\n",
    "def train_and_tune(train_path, validation_path, target_accuracy):\n",
    "    \"\"\"\n",
    "    è‡ªå‹•åŸ·è¡Œå…©éšæ®µè¨“ç·´å’Œè¶…åƒæ•¸èª¿æ•´ã€‚\n",
    "    å¯¦ä½œäº†å¤šé …é·ç§»å­¸ç¿’æœ€ä½³å¯¦è¸ã€‚\n",
    "    \"\"\"\n",
    "    param_space = {\n",
    "        'model_name': [\n",
    "            'MobileNetV3-Large', \n",
    "            # 'EfficientNet-B0'\n",
    "        ],\n",
    "        'learning_rate': [0.001],\n",
    "        'dropout_rate1': [0.5],\n",
    "        'dropout_rate2': [0.3],\n",
    "        'dense_units': [256],\n",
    "        'trainable_layers': [100],\n",
    "\n",
    "        # 'learning_rate': [0.001],\n",
    "        # 'dropout_rate': [0.3],\n",
    "        # 'dense_units': [256],\n",
    "        # 'trainable_layers': [80]\n",
    "    }\n",
    "    \n",
    "    STAGE_1_EPOCHS = 30\n",
    "    STAGE_2_EPOCHS = 50\n",
    "    FINE_TUNE_LR_MULTIPLIER = 0.1\n",
    "    \n",
    "    keys, values = zip(*param_space.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    best_run_id = None\n",
    "\n",
    "    mlflow.set_experiment(\"MobileNetV3æ–°2éšæ®µ RandomErasing 60ç¨®(è³‡æ–™å¤¾7)\")\n",
    "    \n",
    "    for i, params in enumerate(param_combinations):\n",
    "\n",
    "        if best_val_accuracy >= target_accuracy:\n",
    "            print(f\"ğŸ¯ ç›®æ¨™å·²é”æˆ (Accuracy >= {target_accuracy:.2f})ã€‚åœæ­¢æœå°‹ã€‚\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"ğŸš€ Run {i+1}/{len(param_combinations)}: å˜—è©¦åƒæ•¸çµ„åˆ: {params}\")\n",
    "\n",
    "        if params['model_name'] == 'MobileNetV3-Large':\n",
    "            preprocessing_function = mobilenet_v3.preprocess_input\n",
    "        elif params['model_name'] == 'EfficientNet-B0':\n",
    "            preprocessing_function = efficientnet.preprocess_input\n",
    "        else:\n",
    "            raise ValueError(f\"æœªçŸ¥çš„æ¨¡å‹: {params['model_name']}\")\n",
    "\n",
    "        # train_datagen_aug = ImageDataGenerator(\n",
    "        #     preprocessing_function=preprocessing_function,\n",
    "        #     rotation_range=15,\n",
    "        #     width_shift_range=0.1,\n",
    "        #     height_shift_range=0.1,\n",
    "        #     zoom_range=0.1,\n",
    "        #     horizontal_flip=True,\n",
    "        #     # ### å„ªåŒ– 2ï¼šç‚ºé¿å…æ•¸æ“šåˆ†å¸ƒåç§»ï¼Œå»ºè­°å„ªå…ˆç§»é™¤äº®åº¦å¢å¼· ###\n",
    "        #     # brightness_range=[0.9, 1.1],\n",
    "        #     fill_mode='nearest'\n",
    "        # )\n",
    "\n",
    "        train_datagen_simple  = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "\n",
    "        validation_datagen = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "\n",
    "        train_gen = train_datagen_simple.flow_from_directory(\n",
    "            train_path, target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=True\n",
    "        )\n",
    "        val_gen = validation_datagen.flow_from_directory(\n",
    "            validation_path, target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=False\n",
    "        )\n",
    "\n",
    "        num_classes = train_gen.num_classes\n",
    "        class_labels = list(train_gen.class_indices.keys())\n",
    "\n",
    "        with open('classes_new.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for cls in class_labels:\n",
    "                writer.writerow([cls])\n",
    "        \n",
    "        class_indices = np.unique(train_gen.classes)\n",
    "        class_weights_array = compute_class_weight('balanced', classes=class_indices, y=train_gen.classes)\n",
    "        class_weight = dict(zip(class_indices, class_weights_array))\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"{params['model_name']}_run_{i+1}\") as run:\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            # STAGE 1: Feature Extraction\n",
    "            print(\"\\n\" + \"-\" * 20 + \" STAGE 1: Feature Extraction \" + \"-\" * 20)\n",
    "            \n",
    "            # ### å„ªåŒ– 1ï¼šæ¥æ”¶ model å’Œ base_model ###\n",
    "            model, base_model = build_model(\n",
    "                **params, num_classes=num_classes, freeze_base_model=True\n",
    "            )\n",
    "            \n",
    "            history_stage1 = model.fit(\n",
    "                train_gen, epochs=STAGE_1_EPOCHS, validation_data=val_gen,\n",
    "                callbacks=[EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)],\n",
    "                class_weight=class_weight, verbose=1\n",
    "            )\n",
    "            \n",
    "            # STAGE 2: Fine-Tuning\n",
    "            print(\"\\n\" + \"-\" * 20 + \" STAGE 2: Fine-Tuning \" + \"-\" * 20)\n",
    "\n",
    "            # --- ç›´æ¥åœ¨ç¾æœ‰ model ç‰©ä»¶ä¸Šæ“ä½œ ---\n",
    "            base_model.trainable = True\n",
    "            \n",
    "            trainable_layers_count = params['trainable_layers']\n",
    "            if trainable_layers_count > 0 and trainable_layers_count < len(base_model.layers):\n",
    "                print(f\"ğŸ”¥ Fine-tuning: Unfreezing the last {trainable_layers_count} layers.\")\n",
    "                for layer in base_model.layers[:-trainable_layers_count]:\n",
    "                    layer.trainable = False\n",
    "            else:\n",
    "                print(\"ğŸ”¥ Fine-tuning: Unfreezing all base model layers.\")\n",
    "            \n",
    "            # ### å„ªåŒ– 3aï¼šåœ¨å¾®èª¿æ™‚å‡çµ BatchNormalization å±¤ ###\n",
    "            for layer in base_model.layers:\n",
    "                if isinstance(layer, layers.BatchNormalization):\n",
    "                    layer.trainable = False\n",
    "            print(\"ğŸ§Š All BatchNormalization layers in the base model have been frozen.\")\n",
    "\n",
    "            # ç”¨æ›´ä½çš„å­¸ç¿’ç‡é‡æ–°ç·¨è­¯æ¨¡å‹\n",
    "            fine_tune_lr = params['learning_rate'] * FINE_TUNE_LR_MULTIPLIER\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_lr),\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            callbacks_stage2 = [\n",
    "                EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-9),\n",
    "                ModelCheckpoint(\"model_checkpoint.keras\", monitor=\"val_loss\", save_best_only=True)\n",
    "            ]\n",
    "            history_stage2 = model.fit(\n",
    "                train_gen, epochs=STAGE_2_EPOCHS, validation_data=val_gen,\n",
    "                class_weight=class_weight, callbacks=callbacks_stage2, verbose=1\n",
    "            )\n",
    "            \n",
    "            # --- MLflow è¨˜éŒ„ ---\n",
    "            full_history = {}\n",
    "            for key in history_stage1.history.keys():\n",
    "                full_history[key] = history_stage1.history[key] + history_stage2.history[key]\n",
    "            \n",
    "            # ### å„ªåŒ– 3bï¼šè¨ˆç®—æ•´å€‹è¨“ç·´éç¨‹ä¸­çš„æœ€ä½³é©—è­‰æº–ç¢ºç‡ ###\n",
    "            # ç¢ºä¿ history å­—å…¸ä¸æ˜¯ç©ºçš„\n",
    "            best_s1_acc = max(history_stage1.history.get('val_accuracy', [0]))\n",
    "            best_s2_acc = max(history_stage2.history.get('val_accuracy', [0]))\n",
    "            current_run_best_val_accuracy = max(best_s1_acc, best_s2_acc)\n",
    "            \n",
    "            mlflow.log_metric(\"best_val_accuracy\", current_run_best_val_accuracy)\n",
    "            \n",
    "            plot_and_log_history(type('History', (), {'history': full_history})())\n",
    "            evaluate_and_log_all_reports(model, val_gen, class_labels)\n",
    "            mlflow.keras.log_model(model, \"model\")\n",
    "            \n",
    "            print(f\"âœ”ï¸ Run {run.info.run_id} å®Œæˆã€‚æœ¬è¼ªæœ€ä½³é©—è­‰æº–ç¢ºç‡: {current_run_best_val_accuracy:.4f}\")\n",
    "            \n",
    "            if current_run_best_val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = current_run_best_val_accuracy\n",
    "                best_run_id = run.info.run_id\n",
    "                print(f\"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! Model: {params['model_name']}, Run ID: {best_run_id}, Accuracy: {best_val_accuracy:.4f}\")\n",
    "                model.save(f'checkpoints/bestmodel/{i+1}{params['model_name']}_{best_val_accuracy:.4f}.keras')\n",
    "                print(f\"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²æ›´æ–°ä¸¦å„²å­˜ç‚º '{i+1}{params['model_name']}_{best_val_accuracy:.4f}.keras'\")\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ğŸ è‡ªå‹•èª¿åƒå®Œæˆã€‚\")\n",
    "    if best_run_id:\n",
    "        print(f\"ğŸ† æœ€çµ‚æœ€ä½³æ¨¡å‹çš„ Run ID ç‚º: {best_run_id}\")\n",
    "        print(f\"ğŸ† æœ€çµ‚æœ€ä½³é©—è­‰æº–ç¢ºç‡ç‚º: {best_val_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(\"âŒ æœªèƒ½æˆåŠŸè¨“ç·´ä»»ä½•æ¨¡å‹ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e09c9c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/24 22:36:33 INFO mlflow.tracking.fluent: Experiment with name 'MobileNetV3æ–°2éšæ®µ RandomErasing 60ç¨®(è³‡æ–™å¤¾7)' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸš€ Run 1/1: å˜—è©¦åƒæ•¸çµ„åˆ: {'model_name': 'MobileNetV3-Large', 'learning_rate': 0.001, 'dropout_rate1': 0.5, 'dropout_rate2': 0.3, 'dense_units': 256, 'trainable_layers': 100}\n",
      "Found 34279 images belonging to 56 classes.\n",
      "Found 6720 images belonging to 56 classes.\n",
      "\n",
      "-------------------- STAGE 1: Feature Extraction --------------------\n",
      "Epoch 1/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 431ms/step - accuracy: 0.4387 - loss: 1.9668 - val_accuracy: 0.7189 - val_loss: 0.9160\n",
      "Epoch 2/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 363ms/step - accuracy: 0.6077 - loss: 1.2930 - val_accuracy: 0.7574 - val_loss: 0.7851\n",
      "Epoch 3/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 367ms/step - accuracy: 0.6589 - loss: 1.1245 - val_accuracy: 0.7756 - val_loss: 0.7239\n",
      "Epoch 4/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 363ms/step - accuracy: 0.6807 - loss: 1.0444 - val_accuracy: 0.7923 - val_loss: 0.6970\n",
      "Epoch 5/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 359ms/step - accuracy: 0.6994 - loss: 0.9896 - val_accuracy: 0.7897 - val_loss: 0.6736\n",
      "Epoch 6/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 365ms/step - accuracy: 0.7104 - loss: 0.9465 - val_accuracy: 0.8089 - val_loss: 0.6433\n",
      "Epoch 7/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 359ms/step - accuracy: 0.7169 - loss: 0.9172 - val_accuracy: 0.8106 - val_loss: 0.6462\n",
      "Epoch 8/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 366ms/step - accuracy: 0.7304 - loss: 0.8829 - val_accuracy: 0.8073 - val_loss: 0.6503\n",
      "Epoch 9/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 392ms/step - accuracy: 0.7362 - loss: 0.8640 - val_accuracy: 0.8155 - val_loss: 0.6257\n",
      "Epoch 10/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 478ms/step - accuracy: 0.7419 - loss: 0.8498 - val_accuracy: 0.8161 - val_loss: 0.6339\n",
      "Epoch 11/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 500ms/step - accuracy: 0.7489 - loss: 0.8203 - val_accuracy: 0.8207 - val_loss: 0.6031\n",
      "Epoch 12/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 501ms/step - accuracy: 0.7476 - loss: 0.8278 - val_accuracy: 0.8192 - val_loss: 0.6025\n",
      "Epoch 13/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 496ms/step - accuracy: 0.7584 - loss: 0.7877 - val_accuracy: 0.8180 - val_loss: 0.6085\n",
      "Epoch 14/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m527s\u001b[0m 491ms/step - accuracy: 0.7636 - loss: 0.7854 - val_accuracy: 0.8193 - val_loss: 0.5988\n",
      "Epoch 15/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 500ms/step - accuracy: 0.7674 - loss: 0.7800 - val_accuracy: 0.8231 - val_loss: 0.6072\n",
      "Epoch 16/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 499ms/step - accuracy: 0.7684 - loss: 0.7628 - val_accuracy: 0.8266 - val_loss: 0.5867\n",
      "Epoch 17/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 504ms/step - accuracy: 0.7723 - loss: 0.7564 - val_accuracy: 0.8266 - val_loss: 0.5978\n",
      "Epoch 18/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m539s\u001b[0m 503ms/step - accuracy: 0.7747 - loss: 0.7417 - val_accuracy: 0.8188 - val_loss: 0.6158\n",
      "Epoch 19/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 502ms/step - accuracy: 0.7760 - loss: 0.7475 - val_accuracy: 0.8317 - val_loss: 0.5849\n",
      "Epoch 20/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 494ms/step - accuracy: 0.7795 - loss: 0.7241 - val_accuracy: 0.8287 - val_loss: 0.5905\n",
      "Epoch 21/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 485ms/step - accuracy: 0.7826 - loss: 0.7185 - val_accuracy: 0.8214 - val_loss: 0.6172\n",
      "Epoch 22/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 481ms/step - accuracy: 0.7863 - loss: 0.7207 - val_accuracy: 0.8342 - val_loss: 0.5854\n",
      "Epoch 23/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 478ms/step - accuracy: 0.7858 - loss: 0.7108 - val_accuracy: 0.8268 - val_loss: 0.5951\n",
      "Epoch 24/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m537s\u001b[0m 501ms/step - accuracy: 0.7843 - loss: 0.7172 - val_accuracy: 0.8336 - val_loss: 0.5902\n",
      "Epoch 25/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 498ms/step - accuracy: 0.7872 - loss: 0.7042 - val_accuracy: 0.8305 - val_loss: 0.6002\n",
      "Epoch 26/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m522s\u001b[0m 487ms/step - accuracy: 0.7868 - loss: 0.7054 - val_accuracy: 0.8362 - val_loss: 0.5761\n",
      "Epoch 27/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 492ms/step - accuracy: 0.7952 - loss: 0.6832 - val_accuracy: 0.8277 - val_loss: 0.5907\n",
      "Epoch 28/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m575s\u001b[0m 505ms/step - accuracy: 0.7923 - loss: 0.6947 - val_accuracy: 0.8302 - val_loss: 0.5894\n",
      "Epoch 29/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 502ms/step - accuracy: 0.7896 - loss: 0.6990 - val_accuracy: 0.8290 - val_loss: 0.6044\n",
      "Epoch 30/30\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 507ms/step - accuracy: 0.7932 - loss: 0.6944 - val_accuracy: 0.8313 - val_loss: 0.6016\n",
      "\n",
      "-------------------- STAGE 2: Fine-Tuning --------------------\n",
      "ğŸ”¥ Fine-tuning: Unfreezing the last 100 layers.\n",
      "ğŸ§Š All BatchNormalization layers in the base model have been frozen.\n",
      "Epoch 1/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m814s\u001b[0m 745ms/step - accuracy: 0.8348 - loss: 0.5496 - val_accuracy: 0.8622 - val_loss: 0.4922 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 709ms/step - accuracy: 0.8712 - loss: 0.4200 - val_accuracy: 0.8705 - val_loss: 0.4464 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 702ms/step - accuracy: 0.8887 - loss: 0.3650 - val_accuracy: 0.8763 - val_loss: 0.4529 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m758s\u001b[0m 707ms/step - accuracy: 0.9029 - loss: 0.3177 - val_accuracy: 0.8856 - val_loss: 0.4286 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 703ms/step - accuracy: 0.9126 - loss: 0.2896 - val_accuracy: 0.8893 - val_loss: 0.4117 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m750s\u001b[0m 700ms/step - accuracy: 0.9230 - loss: 0.2559 - val_accuracy: 0.8993 - val_loss: 0.3846 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 709ms/step - accuracy: 0.9311 - loss: 0.2296 - val_accuracy: 0.8909 - val_loss: 0.4049 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m766s\u001b[0m 715ms/step - accuracy: 0.9360 - loss: 0.2070 - val_accuracy: 0.8981 - val_loss: 0.3921 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m764s\u001b[0m 713ms/step - accuracy: 0.9382 - loss: 0.2032 - val_accuracy: 0.9045 - val_loss: 0.3955 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m806s\u001b[0m 717ms/step - accuracy: 0.9608 - loss: 0.1241 - val_accuracy: 0.9128 - val_loss: 0.3617 - learning_rate: 2.0000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m799s\u001b[0m 714ms/step - accuracy: 0.9664 - loss: 0.1081 - val_accuracy: 0.9176 - val_loss: 0.3534 - learning_rate: 2.0000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m780s\u001b[0m 727ms/step - accuracy: 0.9679 - loss: 0.1019 - val_accuracy: 0.9179 - val_loss: 0.3611 - learning_rate: 2.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m804s\u001b[0m 729ms/step - accuracy: 0.9688 - loss: 0.0997 - val_accuracy: 0.9162 - val_loss: 0.3641 - learning_rate: 2.0000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m786s\u001b[0m 733ms/step - accuracy: 0.9722 - loss: 0.0872 - val_accuracy: 0.9153 - val_loss: 0.3657 - learning_rate: 2.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m788s\u001b[0m 736ms/step - accuracy: 0.9741 - loss: 0.0812 - val_accuracy: 0.9170 - val_loss: 0.3665 - learning_rate: 4.0000e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m789s\u001b[0m 736ms/step - accuracy: 0.9752 - loss: 0.0787 - val_accuracy: 0.9176 - val_loss: 0.3714 - learning_rate: 4.0000e-06\n",
      "Epoch 17/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m798s\u001b[0m 744ms/step - accuracy: 0.9748 - loss: 0.0779 - val_accuracy: 0.9168 - val_loss: 0.3680 - learning_rate: 4.0000e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m806s\u001b[0m 748ms/step - accuracy: 0.9752 - loss: 0.0791 - val_accuracy: 0.9165 - val_loss: 0.3660 - learning_rate: 8.0000e-07\n",
      "Epoch 19/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m806s\u001b[0m 752ms/step - accuracy: 0.9764 - loss: 0.0752 - val_accuracy: 0.9165 - val_loss: 0.3656 - learning_rate: 8.0000e-07\n",
      "Epoch 20/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m867s\u001b[0m 756ms/step - accuracy: 0.9766 - loss: 0.0742 - val_accuracy: 0.9176 - val_loss: 0.3664 - learning_rate: 8.0000e-07\n",
      "Epoch 21/50\n",
      "\u001b[1m1072/1072\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m811s\u001b[0m 756ms/step - accuracy: 0.9774 - loss: 0.0720 - val_accuracy: 0.9177 - val_loss: 0.3663 - learning_rate: 1.6000e-07\n",
      "âœ… 'history_plots.png' has been logged to MLflow.\n",
      "\n",
      "==================== Starting Full Evaluation for Logging ====================\n",
      "\u001b[1m210/210\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 390ms/step\n",
      "\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "Agaricus lemaneiformis     0.9407    0.9250    0.9328       120\n",
      "              Amaranth     0.8934    0.9083    0.9008       120\n",
      "             Baby Corn     0.9083    0.9083    0.9083       120\n",
      "         Bamboo shoots     0.9120    0.9500    0.9306       120\n",
      "                 Basil     0.8583    0.9083    0.8826       120\n",
      "           Beef Tomato     0.9587    0.9667    0.9627       120\n",
      "           Bell pepper     0.9583    0.9583    0.9583       120\n",
      "   Big Chinese Cabbage     0.9350    0.9583    0.9465       120\n",
      "          Big cucumber     0.9459    0.8750    0.9091       120\n",
      "              Bok Choy     0.9328    0.9250    0.9289       120\n",
      "       Chinese Cabbage     0.9083    0.9083    0.9083       120\n",
      "        Chinese chives     0.8583    0.9083    0.8826       120\n",
      "         Chrysanthemum     0.9076    0.9000    0.9038       120\n",
      "          French beans     0.7338    0.8500    0.7876       120\n",
      "                Garlic     0.9667    0.9667    0.9667       120\n",
      "        Green Broccoli     0.9587    0.9667    0.9627       120\n",
      "   Green bamboo shoots     0.9835    0.9917    0.9876       120\n",
      "          Green pepper     0.9912    0.9417    0.9658       120\n",
      "                  Kale     0.8430    0.8500    0.8465       120\n",
      "               Lettuce     0.9339    0.9417    0.9378       120\n",
      "                Loofah     0.9292    0.8750    0.9013       120\n",
      "            Lotus root     0.9735    0.9167    0.9442       120\n",
      "         Mainland girl     0.8571    0.9500    0.9012       120\n",
      "   Momordica charantia     0.9512    0.9750    0.9630       120\n",
      "           Mountain Su     0.9732    0.9083    0.9397       120\n",
      "                  Okra     0.8421    0.9333    0.8854       120\n",
      "          Red broccoli     0.9369    0.8667    0.9004       120\n",
      "               Romaine     0.9722    0.8750    0.9211       120\n",
      "              Shallots     0.9750    0.9750    0.9750       120\n",
      "             Sweet Pea     0.9279    0.8583    0.8918       120\n",
      "   Sweet potato leaves     0.8074    0.9083    0.8549       120\n",
      "                  Taro     0.9440    0.9833    0.9633       120\n",
      "            Water Lily     0.9832    0.9750    0.9791       120\n",
      "         Water spinach     0.7899    0.9083    0.8450       120\n",
      "          White radish     0.8741    0.9833    0.9255       120\n",
      "          Winter melon     0.9407    0.9250    0.9328       120\n",
      "                   Yam     0.9794    0.7917    0.8756       120\n",
      "             asparagus     0.8760    0.9417    0.9076       120\n",
      "               brocoli     0.9831    0.9667    0.9748       120\n",
      "               cabbage     0.9402    0.9167    0.9283       120\n",
      "                carrot     0.9583    0.9583    0.9583       120\n",
      "                celery     0.8981    0.8083    0.8509       120\n",
      "                 chili     0.9664    0.9583    0.9623       120\n",
      "             coriander     0.8231    0.8917    0.8560       120\n",
      "                  corn     0.9174    0.9250    0.9212       120\n",
      "                cowpea     0.9266    0.8417    0.8821       120\n",
      "              eggplant     0.9664    0.9583    0.9623       120\n",
      "                ginger     0.9593    0.9833    0.9712       120\n",
      "           green onion     0.9712    0.8417    0.9018       120\n",
      "                 onion     0.9504    0.9583    0.9544       120\n",
      "                potato     0.9244    0.9167    0.9205       120\n",
      "               pumpkin     0.9550    0.8833    0.9177       120\n",
      "                  rape     0.8609    0.8250    0.8426       120\n",
      "               spinach     0.8981    0.8083    0.8509       120\n",
      "          sweet potato     0.8692    0.9417    0.9040       120\n",
      "              zucchini     0.8968    0.9417    0.9187       120\n",
      "\n",
      "              accuracy                         0.9176      6720\n",
      "             macro avg     0.9201    0.9176    0.9178      6720\n",
      "          weighted avg     0.9201    0.9176    0.9178      6720\n",
      "\n",
      "âœ… 'classification_report.txt' has been logged to MLflow.\n",
      "âœ… 'confusion_matrix.png' has been logged to MLflow.\n",
      "âœ… 'sorted_correct_counts.png' has been logged to MLflow.\n",
      "âœ… 'precision_recall_curves.png' has been logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/25 07:21:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 'roc_curves.png' has been logged to MLflow.\n",
      "==================== Full Evaluation Logging Complete ====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/25 07:21:35 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/08/25 07:22:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ”ï¸ Run b54019b8cb5b45148a17f75963967e55 å®Œæˆã€‚æœ¬è¼ªæœ€ä½³é©—è­‰æº–ç¢ºç‡: 0.9179\n",
      "ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! Model: MobileNetV3-Large, Run ID: b54019b8cb5b45148a17f75963967e55, Accuracy: 0.9179\n",
      "ğŸ’¾ æœ€ä½³æ¨¡å‹å·²æ›´æ–°ä¸¦å„²å­˜ç‚º '1MobileNetV3-Large_0.9179.keras'\n",
      "======================================================================\n",
      "ğŸ è‡ªå‹•èª¿åƒå®Œæˆã€‚\n",
      "ğŸ† æœ€çµ‚æœ€ä½³æ¨¡å‹çš„ Run ID ç‚º: b54019b8cb5b45148a17f75963967e55\n",
      "ğŸ† æœ€çµ‚æœ€ä½³é©—è­‰æº–ç¢ºç‡ç‚º: 0.9179\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 3. åŸ·è¡Œä¸»æµç¨‹ (å·²æ›´æ–°)\n",
    "\n",
    "# --- å®šç¾©è·¯å¾‘ ---\n",
    "train_path = \"dataset_full_en_aug7_56_new/train\"\n",
    "validation_path = \"dataset_full_en_aug7_56_new/validation\"\n",
    "\n",
    "# --- å•Ÿå‹•è‡ªå‹•è¨“ç·´èˆ‡èª¿åƒ ---\n",
    "if __name__ == '__main__':\n",
    "    # å‡½å¼å…§éƒ¨æœƒè™•ç†æ•¸æ“šç”Ÿæˆå™¨ã€é¡åˆ¥æ•¸é‡å’Œæ¬Šé‡è¨ˆç®—\n",
    "    train_and_tune(\n",
    "        train_path=train_path,\n",
    "        validation_path=validation_path,\n",
    "        target_accuracy=0.98\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef659344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
