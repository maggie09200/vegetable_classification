{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4010c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "import visualkeras\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers, layers, models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint \n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c087ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 1. å»ºç«‹æ¨¡åž‹çš„å‡½å¼\n",
    "def build_model(learning_rate, dropout_rate, dense_units, trainable_layers, num_classes):\n",
    "    \"\"\"\n",
    "    æ ¹æ“šå‚³å…¥çš„è¶…åƒæ•¸å»ºç«‹ MobileNetV2 æ¨¡åž‹ã€‚\n",
    "\n",
    "    åƒæ•¸:\n",
    "    - learning_rate (float): å­¸ç¿’çŽ‡\n",
    "    - dropout_rate (float): Dropout æ¯”çŽ‡\n",
    "    - dense_units (int): å…¨é€£æŽ¥å±¤çš„ç¥žç¶“å…ƒæ•¸é‡\n",
    "    - trainable_layers (int): MobileNetV2 ä¸­å¯è¨“ç·´çš„å±¤æ•¸ (å¾žå¾Œå¾€å‰ç®—)\n",
    "    - num_classes (int): åˆ†é¡žçš„é¡žåˆ¥ç¸½æ•¸\n",
    "    \n",
    "    è¿”å›ž:\n",
    "    - model: å·²ç·¨è­¯çš„ Keras æ¨¡åž‹\n",
    "    \"\"\"\n",
    "    # å»ºç«‹åŸºç¤Žæ¨¡åž‹ MobileNetV2\n",
    "    base_model = keras.applications.MobileNetV2(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # è¨­å®šå¯è¨“ç·´çš„å±¤æ•¸\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-trainable_layers]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # å»ºç«‹åºåˆ—æ¨¡åž‹\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(dense_units, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(dense_units, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # ç·¨è­¯æ¨¡åž‹\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e6a0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# 1. MLflow è¦–è¦ºåŒ–èˆ‡æ—¥èªŒè¨˜éŒ„è¼”åŠ©å‡½å¼\n",
    "# ===================================================================\n",
    "\n",
    "def plot_and_log_history(history, filename=\"history_plots.png\"):\n",
    "    \"\"\"\n",
    "    ç¹ªè£½æº–ç¢ºçŽ‡å’Œæå¤±å‡½æ•¸çš„æ­·å²æ›²ç·šï¼Œä¸¦å°‡å…¶å„²å­˜ç‚ºåœ–ç‰‡ï¼Œæœ€å¾Œè¨˜éŒ„åˆ° MLflowã€‚\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # æº–ç¢ºçŽ‡åœ–\n",
    "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.set_title('Accuracy over epochs')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # æå¤±å‡½æ•¸åœ–\n",
    "    ax2.plot(history.history['loss'], label='Train Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Val Loss')\n",
    "    ax2.set_title('Loss over epochs')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # å„²å­˜åœ–ç‰‡ä¸¦é—œé–‰ç¹ªåœ–\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)  # ç¢ºä¿é—œé–‰æ­£ç¢ºçš„ figure\n",
    "    \n",
    "    # å°‡åœ–ç‰‡è¨˜éŒ„åˆ° MLflow\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"âœ… '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def log_confusion_matrix(y_true, y_pred, class_labels, filename=\"confusion_matrix.png\"):\n",
    "    \"\"\" ç¹ªè£½ã€å„²å­˜ä¸¦è¨˜éŒ„æ¨™æº–æ··æ·†çŸ©é™£ \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(18, 14)) # å¢žåŠ åœ–ç‰‡å¤§å°ä»¥å®¹ç´æ›´å¤šé¡žåˆ¥\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap='Blues')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"âœ… '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def plot_and_log_sorted_confusion_bar(y_true, y_pred, class_labels, filename=\"sorted_correct_counts.png\"):\n",
    "    \"\"\" è¨ˆç®—ã€ç¹ªè£½ä¸¦è¨˜éŒ„ä¸€å€‹é•·æ¢åœ–ï¼Œé¡¯ç¤ºæ¯å€‹é¡žåˆ¥çš„æ­£ç¢ºé æ¸¬æ•¸é‡ï¼ˆç”±é«˜åˆ°ä½ŽæŽ’åºï¼‰ã€‚ \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    correct_counts = np.diag(cm)\n",
    "    \n",
    "    sorted_idx = np.argsort(correct_counts)[::-1]\n",
    "    sorted_counts = correct_counts[sorted_idx]\n",
    "    sorted_labels = np.array(class_labels)[sorted_idx]\n",
    "\n",
    "    plt.figure(figsize=(18, 8)) # å¢žåŠ åœ–ç‰‡å¯¬åº¦\n",
    "    plt.bar(range(len(sorted_counts)), sorted_counts, color='lightgreen')\n",
    "    plt.xticks(range(len(sorted_labels)), sorted_labels, rotation=90)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Correctly Predicted Count')\n",
    "    plt.title('Correctly Predicted Count per Class (sorted)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"âœ… '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def evaluate_and_log_all_reports(model, data_generator, class_labels):\n",
    "    \"\"\"\n",
    "    è©•ä¼°æ¨¡åž‹ä¸¦è¨˜éŒ„åˆ†é¡žå ±å‘Šã€æ··æ·†çŸ©é™£åŠå…¶ä»–åˆ†æžåœ–åˆ° MLflowã€‚\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*20 + \" Starting Full Evaluation for Logging \" + \"=\"*20)\n",
    "\n",
    "    # é—œéµï¼šé‡ç½® generator ä»¥ç¢ºä¿é †åºæ­£ç¢º\n",
    "    data_generator.reset()\n",
    "\n",
    "    # 1. æ¨¡åž‹é æ¸¬\n",
    "    # ä½¿ç”¨ predict() æ–¹æ³•ï¼Œä¸¦æŒ‡å®š stepsï¼Œå¯ä»¥ç¢ºä¿è™•ç†å®Œæ‰€æœ‰æ¨£æœ¬\n",
    "    predictions = model.predict(data_generator, steps=len(data_generator), verbose=1)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # 2. å–å¾—çœŸå¯¦æ¨™ç±¤\n",
    "    # æ³¨æ„ï¼šgenerator çš„ classes å±¬æ€§åŒ…å«äº†æ‰€æœ‰æ¨£æœ¬çš„çœŸå¯¦æ¨™ç±¤\n",
    "    y_true = data_generator.classes\n",
    "\n",
    "    # ç¢ºä¿é•·åº¦ä¸€è‡´ï¼Œé€™åœ¨ generator batch_size ç„¡æ³•æ•´é™¤ç¸½æ¨£æœ¬æ•¸æ™‚å¾ˆé‡è¦\n",
    "    if len(y_pred) != len(y_true):\n",
    "        print(f\"âš ï¸ y_pred length {len(y_pred)} vs y_true length {len(y_true)}. This is normal if batch_size doesn't divide total samples.\")\n",
    "        # `predict` æœƒè™•ç†å®Œæ‰€æœ‰æ¨£æœ¬ï¼Œæ‰€ä»¥ y_true ä¹Ÿæ‡‰è©²æ˜¯å®Œæ•´çš„\n",
    "        y_true = y_true[:len(y_pred)]\n",
    "\n",
    "    # 3. ç”¢ç”Ÿä¸¦è¨˜éŒ„åˆ†é¡žå ±å‘Š\n",
    "    report = classification_report(y_true, y_pred, target_names=class_labels, digits=4, zero_division=0)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    mlflow.log_text(report, \"classification_report.txt\")\n",
    "    print(\"âœ… 'classification_report.txt' has been logged to MLflow.\")\n",
    "\n",
    "    # 4. è¨˜éŒ„æ··æ·†çŸ©é™£\n",
    "    log_confusion_matrix(y_true, y_pred, class_labels)\n",
    "\n",
    "    # 5. è¨˜éŒ„æŽ’åºå¾Œçš„æ­£ç¢ºé æ¸¬æ•¸é‡é•·æ¢åœ–\n",
    "    plot_and_log_sorted_confusion_bar(y_true, y_pred, class_labels)\n",
    "    \n",
    "    print(\"=\"*20 + \" Full Evaluation Logging Complete \" + \"=\"*20 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21242e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 2. è‡ªå‹•è¨“ç·´èˆ‡èª¿åƒçš„ä¸»å‡½å¼ (å·²æ›´æ–°)\n",
    "import itertools\n",
    "\n",
    "def train_and_tune(train_gen, val_gen, class_labels, class_weight, num_classes, target_accuracy=0.9):\n",
    "    \"\"\"\n",
    "    è‡ªå‹•è¨“ç·´å’Œèª¿æ•´è¶…åƒæ•¸ï¼Œç›´åˆ°é©—è­‰æº–ç¢ºçŽ‡é”åˆ°ç›®æ¨™ã€‚\n",
    "    ä½¿ç”¨ MLflow è‡ªå‹•è¨˜éŒ„åƒæ•¸ã€æŒ‡æ¨™ã€åœ–è¡¨å’Œæ¨¡åž‹ã€‚\n",
    "    \"\"\"\n",
    "    # å®šç¾©è¶…åƒæ•¸çš„æœå°‹ç©ºé–“\n",
    "    param_space = {\n",
    "        'learning_rate': [0.0001],\n",
    "        'dropout_rate': [0.5],\n",
    "        'dense_units': [256],\n",
    "        'trainable_layers': [60] # å¾ž MobileNetV2 çš„å¾Œé¢é–‹å§‹è¨“ç·´çš„å±¤æ•¸\n",
    "    }\n",
    "    \n",
    "    keys, values = zip(*param_space.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    best_model = None\n",
    "    best_run_id = None\n",
    "\n",
    "    mlflow.set_experiment(\"vegetable_classification_autotune\")\n",
    "    \n",
    "    for i, params in enumerate(param_combinations):\n",
    "        if best_val_accuracy >= target_accuracy:\n",
    "            print(f\"ðŸŽ¯ ç›®æ¨™å·²é”æˆ (Accuracy >= {target_accuracy:.2f})ã€‚åœæ­¢æœå°‹ã€‚\")\n",
    "            break\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"ðŸš€ Run {i+1}/{len(param_combinations)}: å˜—è©¦åƒæ•¸çµ„åˆ: {params}\")\n",
    "\n",
    "        with mlflow.start_run() as run:\n",
    "            # è¨˜éŒ„è¶…åƒæ•¸\n",
    "            mlflow.log_params(params)\n",
    "            \n",
    "            # å»ºç«‹ä¸¦ç·¨è­¯æ¨¡åž‹\n",
    "            model = build_model(num_classes=num_classes, **params)\n",
    "            \n",
    "            # è¨­å®šå›žå‘¼å‡½å¼\n",
    "            early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-8)\n",
    "            checkpoint = tf.keras.callbacks.ModelCheckpoint(\"model_checkpoint.keras\", monitor=\"val_loss\", save_best_only=True)\n",
    "            \n",
    "            # æ¨¡åž‹è¨“ç·´\n",
    "            history = model.fit(\n",
    "                train_gen,\n",
    "                epochs=30,\n",
    "                validation_data=val_gen,\n",
    "                class_weight=class_weight,\n",
    "                callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # === MLflow è¨˜éŒ„å€ ===\n",
    "            \n",
    "            # 1. è¨˜éŒ„ä¸»è¦æŒ‡æ¨™\n",
    "            val_accuracy = max(history.history['val_accuracy'])\n",
    "            mlflow.log_metric(\"best_val_accuracy\", val_accuracy)\n",
    "            mlflow.log_metric(\"final_train_accuracy\", history.history['accuracy'][-1])\n",
    "            mlflow.log_metric(\"stopped_epoch\", len(history.history['val_accuracy']))\n",
    "\n",
    "            # 2. è¨˜éŒ„è¨“ç·´æ­·å²åœ–è¡¨\n",
    "            plot_and_log_history(history)\n",
    "            \n",
    "            # 3. è¨˜éŒ„å®Œæ•´çš„è©•ä¼°å ±å‘Š (æ··æ·†çŸ©é™£, åˆ†é¡žå ±å‘Šç­‰)\n",
    "            # ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡åž‹ (EarlyStopping æœƒè‡ªå‹•é‚„åŽŸæœ€ä½³æ¬Šé‡)\n",
    "            evaluate_and_log_all_reports(model, val_gen, class_labels)\n",
    "            \n",
    "            # 4. è¨˜éŒ„æ¨¡åž‹\n",
    "            mlflow.keras.log_model(model, \"model\", signature=None) # signature=False å¯ä»¥åŠ å¿«å„²å­˜é€Ÿåº¦\n",
    "            \n",
    "            print(f\"âœ”ï¸ Run {run.info.run_id} å®Œæˆã€‚æœ€ä½³é©—è­‰æº–ç¢ºçŽ‡: {val_accuracy:.4f}\")\n",
    "            \n",
    "            # æ›´æ–°å…¨å±€æœ€ä½³æ¨¡åž‹\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                best_model = model\n",
    "                best_run_id = run.info.run_id\n",
    "                print(f\"ðŸŽ‰ æ–°çš„æœ€ä½³æ¨¡åž‹! Run ID: {best_run_id}, Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ðŸ è‡ªå‹•èª¿åƒå®Œæˆã€‚\")\n",
    "    if best_model:\n",
    "        print(f\"ðŸ† æœ€çµ‚æœ€ä½³æ¨¡åž‹çš„ Run ID ç‚º: {best_run_id}\")\n",
    "        print(f\"ðŸ† æœ€çµ‚æœ€ä½³é©—è­‰æº–ç¢ºçŽ‡ç‚º: {best_val_accuracy:.4f}\")\n",
    "        best_model.save('best_tuned_model.h5')\n",
    "        print(\"ðŸ’¾ æœ€ä½³æ¨¡åž‹å·²å„²å­˜ç‚º 'best_tuned_model.h5'\")\n",
    "    else:\n",
    "        print(\"âŒ æœªèƒ½æˆåŠŸè¨“ç·´ä»»ä½•æ¨¡åž‹ã€‚\")\n",
    "        \n",
    "    return best_model, best_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09adec77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26307 images belonging to 60 classes.\n",
      "Found 7514 images belonging to 60 classes.\n",
      "------------------------------------------------------------\n",
      "ðŸš€ Run 1/1: å˜—è©¦åƒæ•¸çµ„åˆ: {'learning_rate': 0.0001, 'dropout_rate': 0.5, 'dense_units': 256, 'trainable_layers': 60}\n",
      "Epoch 1/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 647ms/step - accuracy: 0.0831 - loss: 3.8904 - val_accuracy: 0.4952 - val_loss: 1.8341 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 638ms/step - accuracy: 0.4202 - loss: 2.1947 - val_accuracy: 0.6590 - val_loss: 1.1882 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 638ms/step - accuracy: 0.5720 - loss: 1.5841 - val_accuracy: 0.6928 - val_loss: 1.0851 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 637ms/step - accuracy: 0.6575 - loss: 1.2514 - val_accuracy: 0.7167 - val_loss: 1.0565 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 637ms/step - accuracy: 0.7054 - loss: 1.0796 - val_accuracy: 0.7585 - val_loss: 0.8764 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 632ms/step - accuracy: 0.7529 - loss: 0.9201 - val_accuracy: 0.7616 - val_loss: 0.9157 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 636ms/step - accuracy: 0.7762 - loss: 0.8173 - val_accuracy: 0.7844 - val_loss: 0.8266 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 636ms/step - accuracy: 0.7995 - loss: 0.7348 - val_accuracy: 0.7925 - val_loss: 0.8217 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 607ms/step - accuracy: 0.8173 - loss: 0.6670 - val_accuracy: 0.8022 - val_loss: 0.8070 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 602ms/step - accuracy: 0.8401 - loss: 0.5882 - val_accuracy: 0.7970 - val_loss: 0.8599 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 565ms/step - accuracy: 0.8533 - loss: 0.5335 - val_accuracy: 0.8096 - val_loss: 0.7799 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 564ms/step - accuracy: 0.8600 - loss: 0.5105 - val_accuracy: 0.8032 - val_loss: 0.7784 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 561ms/step - accuracy: 0.8757 - loss: 0.4470 - val_accuracy: 0.7912 - val_loss: 0.8513 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 564ms/step - accuracy: 0.8846 - loss: 0.4227 - val_accuracy: 0.7855 - val_loss: 0.9361 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 561ms/step - accuracy: 0.8915 - loss: 0.4054 - val_accuracy: 0.8118 - val_loss: 0.7796 - learning_rate: 1.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 566ms/step - accuracy: 0.9139 - loss: 0.3118 - val_accuracy: 0.8411 - val_loss: 0.6705 - learning_rate: 2.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 562ms/step - accuracy: 0.9236 - loss: 0.2697 - val_accuracy: 0.8470 - val_loss: 0.6566 - learning_rate: 2.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 565ms/step - accuracy: 0.9289 - loss: 0.2527 - val_accuracy: 0.8462 - val_loss: 0.6620 - learning_rate: 2.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 562ms/step - accuracy: 0.9339 - loss: 0.2408 - val_accuracy: 0.8516 - val_loss: 0.6480 - learning_rate: 2.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 566ms/step - accuracy: 0.9385 - loss: 0.2250 - val_accuracy: 0.8519 - val_loss: 0.6581 - learning_rate: 2.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 562ms/step - accuracy: 0.9431 - loss: 0.2088 - val_accuracy: 0.8507 - val_loss: 0.6502 - learning_rate: 2.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 566ms/step - accuracy: 0.9425 - loss: 0.2099 - val_accuracy: 0.8475 - val_loss: 0.6571 - learning_rate: 2.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 561ms/step - accuracy: 0.9446 - loss: 0.1950 - val_accuracy: 0.8509 - val_loss: 0.6544 - learning_rate: 4.0000e-06\n",
      "Epoch 24/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 564ms/step - accuracy: 0.9478 - loss: 0.1851 - val_accuracy: 0.8517 - val_loss: 0.6548 - learning_rate: 4.0000e-06\n",
      "Epoch 25/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 560ms/step - accuracy: 0.9469 - loss: 0.1884 - val_accuracy: 0.8521 - val_loss: 0.6597 - learning_rate: 4.0000e-06\n",
      "Epoch 26/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 563ms/step - accuracy: 0.9519 - loss: 0.1796 - val_accuracy: 0.8532 - val_loss: 0.6592 - learning_rate: 8.0000e-07\n",
      "Epoch 27/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 560ms/step - accuracy: 0.9495 - loss: 0.1794 - val_accuracy: 0.8533 - val_loss: 0.6597 - learning_rate: 8.0000e-07\n",
      "âœ… 'history_plots.png' has been logged to MLflow.\n",
      "\n",
      "==================== Starting Full Evaluation for Logging ====================\n",
      "\u001b[1m235/235\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 262ms/step\n",
      "\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "Agaricus lemaneiformis     0.8607    0.8750    0.8678       120\n",
      "              Amaranth     0.9076    0.8780    0.8926       123\n",
      "             Baby Corn     0.9247    0.9060    0.9153       149\n",
      "         Bamboo shoots     0.8443    0.8583    0.8512       120\n",
      "                 Basil     0.7586    0.9244    0.8333       119\n",
      "           Beef Tomato     0.9431    0.9667    0.9547       120\n",
      "           Bell pepper     0.9496    0.9496    0.9496       119\n",
      "   Big Chinese Cabbage     0.7054    0.7583    0.7309       120\n",
      "          Big cucumber     0.7949    0.7750    0.7848       120\n",
      "              Bok Choy     0.7857    0.9167    0.8462       120\n",
      "       Chinese Cabbage     0.8070    0.7667    0.7863       120\n",
      "        Chinese chives     0.7982    0.7250    0.7598       120\n",
      "         Chrysanthemum     0.9700    0.8083    0.8818       120\n",
      "              Cucumber     0.8103    0.7833    0.7966       120\n",
      "          French beans     0.7615    0.7615    0.7615       130\n",
      "                Garlic     0.9621    0.8699    0.9137       146\n",
      "        Garlic sprouts     0.6852    0.6167    0.6491       120\n",
      "        Green Broccoli     0.9521    0.9392    0.9456       148\n",
      "   Green bamboo shoots     0.9421    0.9500    0.9461       120\n",
      "          Green pepper     0.8843    0.8917    0.8880       120\n",
      "                  Kale     0.8365    0.7250    0.7768       120\n",
      "               Lettuce     0.8750    0.8750    0.8750       120\n",
      "                Loofah     0.8115    0.8250    0.8182       120\n",
      "            Lotus root     0.9068    0.8917    0.8992       120\n",
      "         Mainland girl     0.8136    0.8000    0.8067       120\n",
      "   Momordica charantia     0.9725    0.8833    0.9258       120\n",
      "           Mountain Su     0.8655    0.8583    0.8619       120\n",
      "                  Okra     0.9141    0.8660    0.8894       209\n",
      "          Red broccoli     0.9464    0.8833    0.9138       120\n",
      "               Romaine     0.8760    0.8833    0.8797       120\n",
      "              Shallots     0.9204    0.8667    0.8927       120\n",
      "             Sweet Pea     0.7407    0.8333    0.7843       120\n",
      "   Sweet potato leaves     0.7752    0.8333    0.8032       120\n",
      "                  Taro     0.9455    0.8667    0.9043       120\n",
      "           WaWa dishes     0.8519    0.7667    0.8070       120\n",
      "            Water Lily     0.9832    0.9750    0.9791       120\n",
      "         Water spinach     0.8293    0.8160    0.8226       125\n",
      "          White radish     0.9337    0.9385    0.9361       195\n",
      "          Winter melon     0.7737    0.8833    0.8249       120\n",
      "                   Yam     0.8879    0.7917    0.8370       120\n",
      "             asparagus     0.9481    0.8538    0.8985       171\n",
      "               brocoli     0.9524    0.8333    0.8889       120\n",
      "               cabbage     0.7983    0.7917    0.7950       120\n",
      "                carrot     0.9496    0.9417    0.9456       120\n",
      "                celery     0.8000    0.8333    0.8163       120\n",
      "                 chili     0.9160    0.9083    0.9121       120\n",
      "             coriander     0.8972    0.8000    0.8458       120\n",
      "                  corn     0.8636    0.9500    0.9048       120\n",
      "                cowpea     0.7519    0.8083    0.7791       120\n",
      "              eggplant     0.8852    0.9000    0.8926       120\n",
      "                ginger     0.8409    0.9250    0.8810       120\n",
      "           green onion     0.6125    0.8167    0.7000       120\n",
      "                 onion     0.7355    0.9500    0.8291       120\n",
      "                   pea     0.8636    0.7917    0.8261       120\n",
      "                potato     0.8346    0.9250    0.8775       120\n",
      "               pumpkin     0.9459    0.8750    0.9091       120\n",
      "                  rape     0.6058    0.6917    0.6459       120\n",
      "               spinach     0.7638    0.8083    0.7854       120\n",
      "          sweet potato     0.8922    0.7583    0.8198       120\n",
      "              zucchini     0.8655    0.8583    0.8619       120\n",
      "\n",
      "              accuracy                         0.8516      7514\n",
      "             macro avg     0.8538    0.8500    0.8501      7514\n",
      "          weighted avg     0.8569    0.8516    0.8525      7514\n",
      "\n",
      "âœ… 'classification_report.txt' has been logged to MLflow.\n",
      "âœ… 'confusion_matrix.png' has been logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/08 03:23:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/08 03:23:13 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 'sorted_correct_counts.png' has been logged to MLflow.\n",
      "==================== Full Evaluation Logging Complete ====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/08 03:23:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ”ï¸ Run c4a51c5302844401a7e5ea537b444a6f å®Œæˆã€‚æœ€ä½³é©—è­‰æº–ç¢ºçŽ‡: 0.8533\n",
      "ðŸŽ‰ æ–°çš„æœ€ä½³æ¨¡åž‹! Run ID: c4a51c5302844401a7e5ea537b444a6f, Accuracy: 0.8533\n",
      "============================================================\n",
      "ðŸ è‡ªå‹•èª¿åƒå®Œæˆã€‚\n",
      "ðŸ† æœ€çµ‚æœ€ä½³æ¨¡åž‹çš„ Run ID ç‚º: c4a51c5302844401a7e5ea537b444a6f\n",
      "ðŸ† æœ€çµ‚æœ€ä½³é©—è­‰æº–ç¢ºçŽ‡ç‚º: 0.8533\n",
      "ðŸ’¾ æœ€ä½³æ¨¡åž‹å·²å„²å­˜ç‚º 'best_tuned_model.h5'\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 3. åŸ·è¡Œä¸»æµç¨‹ (å·²æ›´æ–°)\n",
    "\n",
    "# --- è³‡æ–™æº–å‚™ ---\n",
    "train_path = \"dataset_full_en/train\"\n",
    "validation_path = \"dataset_full_en/validation\"\n",
    "num_classes = len(os.listdir(train_path))\n",
    "\n",
    "train_datagen_aug = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator_aug = train_datagen_aug.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True # è¨“ç·´é›†éœ€è¦ shuffle\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False # é©—è­‰/æ¸¬è©¦é›†çµ•ä¸èƒ½ shuffleï¼Œä»¥ç¢ºä¿æ¨™ç±¤é †åºæ­£ç¢º\n",
    ")\n",
    "\n",
    "\n",
    "# å¾ž generator ä¸­ç²å–é¡žåˆ¥åç¨±å’Œç´¢å¼•çš„å°æ‡‰é—œä¿‚\n",
    "class_labels = list(train_generator_aug.class_indices.keys())\n",
    "\n",
    "# è¨ˆç®— class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_indices = np.unique(train_generator_aug.classes)\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=class_indices,\n",
    "    y=train_generator_aug.classes\n",
    ")\n",
    "class_weight_dict = dict(zip(class_indices, class_weights_array))\n",
    "\n",
    "\n",
    "# --- å•Ÿå‹•è‡ªå‹•è¨“ç·´èˆ‡èª¿åƒ ---\n",
    "if __name__ == '__main__':\n",
    "    # å°‡æ‰€æœ‰éœ€è¦çš„åƒæ•¸å‚³å…¥\n",
    "    best_model, best_accuracy = train_and_tune(\n",
    "        train_gen=train_generator_aug,\n",
    "        val_gen=validation_generator,\n",
    "        class_labels=class_labels,\n",
    "        class_weight=class_weight_dict,\n",
    "        num_classes=num_classes,\n",
    "        target_accuracy=0.90\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f26924",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbest_model\u001b[49m.save(\u001b[33m'\u001b[39m\u001b[33mmodel_mnV2(best).keras\u001b[39m\u001b[33m'\u001b[39m) \n",
      "\u001b[31mNameError\u001b[39m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_model.save('model_mnV2(best).keras') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
