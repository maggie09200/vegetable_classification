{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d8ad028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "import visualkeras\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from tensorflow.keras.applications import mobilenet_v3, efficientnet\n",
    "import itertools # 確保 itertools 已匯入\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers, layers, models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint \n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70b5b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 1. 建立模型的函式 (已更新，支援兩階段訓練的凍結控制)\n",
    "def build_model(model_name, learning_rate, dropout_rate, dense_units, trainable_layers, num_classes, freeze_base_model=False):\n",
    "    \"\"\"\n",
    "    根據傳入的超參數建立並編譯指定的 Keras 模型。\n",
    "    *** 使用 Functional API 以確保模型結構的穩健性 ***\n",
    "    \"\"\"\n",
    "    input_shape = (224, 224, 3)\n",
    "    \n",
    "    # 定義模型輸入\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # 根據 model_name 選擇並建立基礎模型\n",
    "    if model_name == 'MobileNetV3-Large':\n",
    "        base_model = keras.applications.MobileNetV3Large(\n",
    "            input_shape=input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            # 關鍵：將 base_model 的輸入與我們定義的 `inputs` 張量連接起來\n",
    "            input_tensor=inputs \n",
    "        )\n",
    "        print(\"✅ Base model loaded: MobileNetV3-Large\")\n",
    "    elif model_name == 'EfficientNet-B0':\n",
    "        base_model = keras.applications.EfficientNetB0(\n",
    "            input_shape=input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            # 關鍵：將 base_model 的輸入與我們定義的 `inputs` 張量連接起來\n",
    "            input_tensor=inputs\n",
    "        )\n",
    "        print(\"✅ Base model loaded: EfficientNetB0\")\n",
    "    else:\n",
    "        raise ValueError(f\"不支援的模型名稱: {model_name}。\")\n",
    "        \n",
    "    # --- 設定基底模型的可訓練性 ---\n",
    "    if freeze_base_model:\n",
    "        base_model.trainable = False\n",
    "        print(\"🧊 Stage 1: Base model is FROZEN.\")\n",
    "    else:\n",
    "        base_model.trainable = True\n",
    "        if trainable_layers > 0 and trainable_layers < len(base_model.layers):\n",
    "            for layer in base_model.layers[:-trainable_layers]:\n",
    "                layer.trainable = False\n",
    "            print(f\"🔥 Stage 2: Fine-tuning. Last {trainable_layers} layers of base model are UNFROZEN.\")\n",
    "        else:\n",
    "            print(\"🔥 Stage 2: Fine-tuning. All layers of base model are UNFROZEN.\")\n",
    "\n",
    "    # --- 使用 Functional API 串接模型 ---\n",
    "    # 取得 base_model 的輸出\n",
    "    x = base_model.output\n",
    "    # 連接到後續的層\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(dense_units, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(dense_units, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    # 輸出層\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # 建立最終模型，明確指定輸入和輸出\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 編譯模型 (需要使用 Adam 的實例，而不是字串 'Adam')\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b38f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MLflow 視覺化與日誌記錄輔助函式 (維持不變)\n",
    "\n",
    "def plot_and_log_history(history, filename=\"history_plots.png\"):\n",
    "    \"\"\"\n",
    "    繪製準確率和損失函數的歷史曲線，並將其儲存為圖片，最後記錄到 MLflow。\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 準確率圖\n",
    "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.set_title('Accuracy over epochs')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # 損失函數圖\n",
    "    ax2.plot(history.history['loss'], label='Train Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Val Loss')\n",
    "    ax2.set_title('Loss over epochs')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # 儲存圖片並關閉繪圖\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)  # 確保關閉正確的 figure\n",
    "    \n",
    "    # 將圖片記錄到 MLflow\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"✅ '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def log_confusion_matrix(y_true, y_pred, class_labels, filename=\"confusion_matrix.png\"):\n",
    "    \"\"\" 繪製、儲存並記錄標準混淆矩陣 \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(18, 14)) # 增加圖片大小以容納更多類別\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap='Blues')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"✅ '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def plot_and_log_sorted_confusion_bar(y_true, y_pred, class_labels, filename=\"sorted_correct_counts.png\"):\n",
    "    \"\"\" 計算、繪製並記錄一個長條圖，顯示每個類別的正確預測數量（由高到低排序）。 \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    correct_counts = np.diag(cm)\n",
    "    \n",
    "    sorted_idx = np.argsort(correct_counts)[::-1]\n",
    "    sorted_counts = correct_counts[sorted_idx]\n",
    "    sorted_labels = np.array(class_labels)[sorted_idx]\n",
    "\n",
    "    plt.figure(figsize=(18, 8)) # 增加圖片寬度\n",
    "    plt.bar(range(len(sorted_counts)), sorted_counts, color='lightgreen')\n",
    "    plt.xticks(range(len(sorted_labels)), sorted_labels, rotation=90)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Correctly Predicted Count')\n",
    "    plt.title('Correctly Predicted Count per Class (sorted)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"✅ '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def evaluate_and_log_all_reports(model, data_generator, class_labels):\n",
    "    \"\"\"\n",
    "    評估模型並記錄分類報告、混淆矩陣及其他分析圖到 MLflow。\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*20 + \" Starting Full Evaluation for Logging \" + \"=\"*20)\n",
    "\n",
    "    # 關鍵：重置 generator 以確保順序正確\n",
    "    data_generator.reset()\n",
    "\n",
    "    # 1. 模型預測\n",
    "    # 使用 predict() 方法，並指定 steps，可以確保處理完所有樣本\n",
    "    predictions = model.predict(data_generator, steps=len(data_generator), verbose=1)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # 2. 取得真實標籤\n",
    "    # 注意：generator 的 classes 屬性包含了所有樣本的真實標籤\n",
    "    y_true = data_generator.classes\n",
    "\n",
    "    # 確保長度一致，這在 generator batch_size 無法整除總樣本數時很重要\n",
    "    if len(y_pred) != len(y_true):\n",
    "        print(f\"⚠️ y_pred length {len(y_pred)} vs y_true length {len(y_true)}. This is normal if batch_size doesn't divide total samples.\")\n",
    "        # `predict` 會處理完所有樣本，所以 y_true 也應該是完整的\n",
    "        y_true = y_true[:len(y_pred)]\n",
    "\n",
    "    # 3. 產生並記錄分類報告\n",
    "    report = classification_report(y_true, y_pred, target_names=class_labels, digits=4, zero_division=0)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    mlflow.log_text(report, \"classification_report.txt\")\n",
    "    print(\"✅ 'classification_report.txt' has been logged to MLflow.\")\n",
    "\n",
    "    # 4. 記錄混淆矩陣\n",
    "    log_confusion_matrix(y_true, y_pred, class_labels)\n",
    "\n",
    "    # 5. 記錄排序後的正確預測數量長條圖\n",
    "    plot_and_log_sorted_confusion_bar(y_true, y_pred, class_labels)\n",
    "    \n",
    "    print(\"=\"*20 + \" Full Evaluation Logging Complete \" + \"=\"*20 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ad3f6",
   "metadata": {},
   "source": [
    "### 兩種模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b30e6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 2. 自動訓練與調參的主函式 (已更新為使用 preprocess_input)\n",
    "def train_and_tune(train_path, validation_path, target_accuracy):\n",
    "    \"\"\"\n",
    "    自動執行兩階段訓練和超參數調整。\n",
    "    為每個模型動態創建使用其專屬 preprocess_input 的數據生成器。\n",
    "    \"\"\"\n",
    "    # 定義超參數的搜尋空間\n",
    "    param_space = {\n",
    "        'model_name': [\n",
    "            'MobileNetV3-Large', \n",
    "            # 'EfficientNet-B0'\n",
    "            ],\n",
    "        'learning_rate': [0.001],\n",
    "        'dropout_rate': [0.3],\n",
    "        'dense_units': [256],\n",
    "        'trainable_layers': [80]  # 可調整的層數\n",
    "    }\n",
    "    \n",
    "    STAGE_1_EPOCHS = 30\n",
    "    STAGE_2_EPOCHS = 50\n",
    "    FINE_TUNE_LR_MULTIPLIER = 0.1\n",
    "    \n",
    "    keys, values = zip(*param_space.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    best_run_id = None\n",
    "\n",
    "    mlflow.set_experiment(\"MobileNetV3 單階段 資料集2(60)\")\n",
    "    \n",
    "    for i, params in enumerate(param_combinations):\n",
    "        if best_val_accuracy >= target_accuracy:\n",
    "            print(f\"🎯 目標已達成 (Accuracy >= {target_accuracy:.2f})。停止搜尋。\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"🚀 Run {i+1}/{len(param_combinations)}: 嘗試參數組合: {params}\")\n",
    "\n",
    "        # --- 關鍵修改：根據模型名稱選擇預處理函式 ---\n",
    "        if params['model_name'] == 'MobileNetV3-Large':\n",
    "            preprocessing_function = mobilenet_v3.preprocess_input\n",
    "            print(\"INFO: Using MobileNetV3 preprocess_input.\")\n",
    "        elif params['model_name'] == 'EfficientNet-B0':\n",
    "            preprocessing_function = efficientnet.preprocess_input\n",
    "            print(\"INFO: Using EfficientNet preprocess_input.\")\n",
    "        else:\n",
    "            raise ValueError(f\"未知的模型: {params['model_name']}\")\n",
    "\n",
    "        # --- 在迴圈內部創建數據生成器 ---\n",
    "        train_datagen_aug = ImageDataGenerator(\n",
    "            preprocessing_function=preprocessing_function,  # 使用指定的函式\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            brightness_range=[0.9, 1.1],\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        \n",
    "        validation_datagen = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "\n",
    "        train_gen = train_datagen_aug.flow_from_directory(\n",
    "            train_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        val_gen = validation_datagen.flow_from_directory(\n",
    "            validation_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        # 從生成器獲取數據集信息\n",
    "        num_classes = train_gen.num_classes\n",
    "        class_labels = list(train_gen.class_indices.keys())\n",
    "\n",
    "        # 儲存類別名稱到 classes.csv\n",
    "        with open('classes_new.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for cls in class_labels:\n",
    "                writer.writerow([cls])\n",
    "        \n",
    "        # 計算 class_weight\n",
    "        class_indices = np.unique(train_gen.classes)\n",
    "        class_weights_array = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=class_indices,\n",
    "            y=train_gen.classes\n",
    "        )\n",
    "        class_weight = dict(zip(class_indices, class_weights_array))\n",
    "\n",
    "        # --- 訓練流程（與之前相同） ---\n",
    "        with mlflow.start_run(run_name=f\"{params['model_name']}_run_{i+1}\") as run:\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-9),\n",
    "                ModelCheckpoint(\"model_checkpoint.keras\", monitor=\"val_loss\", save_best_only=True)\n",
    "            ]\n",
    "            \n",
    "            # STAGE 1: 訓練分類頭\n",
    "            # print(\"\\n\" + \"-\" * 20 + \" STAGE 1: Feature Extraction \" + \"-\" * 20)\n",
    "            model = build_model(\n",
    "                **params, \n",
    "                num_classes=num_classes, \n",
    "                freeze_base_model=False\n",
    "                )\n",
    "            \n",
    "            history_stage1 = model.fit(\n",
    "                train_gen, \n",
    "                epochs=STAGE_1_EPOCHS, \n",
    "                validation_data=val_gen, \n",
    "                callbacks=callbacks, \n",
    "                class_weight=class_weight, \n",
    "                verbose=1\n",
    "                )\n",
    "            \n",
    "            \n",
    "            # MLflow 記錄\n",
    "            val_accuracy = max(history_stage1.history['val_accuracy'])\n",
    "            mlflow.log_metric(\"best_val_accuracy\", val_accuracy)\n",
    "            \n",
    "            plot_and_log_history(history_stage1)\n",
    "            evaluate_and_log_all_reports(model, val_gen, class_labels)\n",
    "            mlflow.keras.log_model(model, \"model\")\n",
    "            \n",
    "            print(f\"✔️ Run {run.info.run_id} 完成。最佳驗證準確率: {val_accuracy:.4f}\")\n",
    "            \n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                best_run_id = run.info.run_id\n",
    "                print(f\"🎉 新的最佳模型! Model: {params['model_name']}, Run ID: {best_run_id}, Accuracy: {best_val_accuracy:.4f}\")\n",
    "                model.save(f'checkpoints/bestmodel/{i+1}{params['model_name']}_{best_val_accuracy:.4f}.keras')\n",
    "                print(f\"💾 最佳模型已更新並儲存為 '{i+1}{params['model_name']}_{best_val_accuracy:.4f}.keras'\")\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"🏁 自動調參完成。\")\n",
    "    if best_run_id:\n",
    "        print(f\"🏆 最終最佳模型的 Run ID 為: {best_run_id}\")\n",
    "        print(f\"🏆 最終最佳驗證準確率為: {best_val_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(\"❌ 未能成功訓練任何模型。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e09c9c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 Run 1/1: 嘗試參數組合: {'model_name': 'MobileNetV3-Large', 'learning_rate': 0.001, 'dropout_rate': 0.3, 'dense_units': 256, 'trainable_layers': 80}\n",
      "INFO: Using MobileNetV3 preprocess_input.\n",
      "Found 26307 images belonging to 60 classes.\n",
      "Found 7514 images belonging to 60 classes.\n",
      "✅ Base model loaded: MobileNetV3-Large\n",
      "🔥 Stage 2: Fine-tuning. Last 80 layers of base model are UNFROZEN.\n",
      "Epoch 1/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1250s\u001b[0m 1s/step - accuracy: 0.5087 - loss: 1.8238 - val_accuracy: 0.3352 - val_loss: 22.3606 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1338s\u001b[0m 2s/step - accuracy: 0.7175 - loss: 0.9922 - val_accuracy: 0.4138 - val_loss: 24.4261 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1339s\u001b[0m 2s/step - accuracy: 0.7731 - loss: 0.7967 - val_accuracy: 0.5426 - val_loss: 7.7709 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1249s\u001b[0m 2s/step - accuracy: 0.8045 - loss: 0.6913 - val_accuracy: 0.5293 - val_loss: 9.5688 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1332s\u001b[0m 2s/step - accuracy: 0.8249 - loss: 0.6086 - val_accuracy: 0.6699 - val_loss: 12.8158 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1331s\u001b[0m 2s/step - accuracy: 0.8419 - loss: 0.5511 - val_accuracy: 0.6163 - val_loss: 3.9725 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1202s\u001b[0m 1s/step - accuracy: 0.8564 - loss: 0.5013 - val_accuracy: 0.7441 - val_loss: 1.4543 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1367s\u001b[0m 2s/step - accuracy: 0.8680 - loss: 0.4567 - val_accuracy: 0.6805 - val_loss: 2.2000 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1518s\u001b[0m 2s/step - accuracy: 0.8830 - loss: 0.4092 - val_accuracy: 0.7241 - val_loss: 2.5345 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1476s\u001b[0m 2s/step - accuracy: 0.8860 - loss: 0.3872 - val_accuracy: 0.7529 - val_loss: 1.1142 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1500s\u001b[0m 2s/step - accuracy: 0.8927 - loss: 0.3762 - val_accuracy: 0.7785 - val_loss: 0.9895 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1492s\u001b[0m 2s/step - accuracy: 0.9020 - loss: 0.3422 - val_accuracy: 0.7723 - val_loss: 0.9971 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1493s\u001b[0m 2s/step - accuracy: 0.9053 - loss: 0.3328 - val_accuracy: 0.7899 - val_loss: 0.9376 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1499s\u001b[0m 2s/step - accuracy: 0.9100 - loss: 0.3129 - val_accuracy: 0.7129 - val_loss: 1.3085 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1526s\u001b[0m 2s/step - accuracy: 0.9171 - loss: 0.2934 - val_accuracy: 0.8094 - val_loss: 0.9145 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1496s\u001b[0m 2s/step - accuracy: 0.9170 - loss: 0.2894 - val_accuracy: 0.7958 - val_loss: 1.0534 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1488s\u001b[0m 2s/step - accuracy: 0.9211 - loss: 0.2821 - val_accuracy: 0.7812 - val_loss: 1.0030 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1520s\u001b[0m 2s/step - accuracy: 0.9271 - loss: 0.2523 - val_accuracy: 0.8324 - val_loss: 0.7276 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1729s\u001b[0m 2s/step - accuracy: 0.9275 - loss: 0.2492 - val_accuracy: 0.8331 - val_loss: 0.7680 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1726s\u001b[0m 2s/step - accuracy: 0.9306 - loss: 0.2406 - val_accuracy: 0.8076 - val_loss: 0.8753 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1767s\u001b[0m 2s/step - accuracy: 0.9328 - loss: 0.2354 - val_accuracy: 0.8311 - val_loss: 0.8597 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1711s\u001b[0m 2s/step - accuracy: 0.9648 - loss: 0.1159 - val_accuracy: 0.8836 - val_loss: 0.5470 - learning_rate: 2.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1212s\u001b[0m 1s/step - accuracy: 0.9767 - loss: 0.0809 - val_accuracy: 0.8901 - val_loss: 0.5371 - learning_rate: 2.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1214s\u001b[0m 1s/step - accuracy: 0.9795 - loss: 0.0658 - val_accuracy: 0.8862 - val_loss: 0.5938 - learning_rate: 2.0000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1214s\u001b[0m 1s/step - accuracy: 0.9805 - loss: 0.0614 - val_accuracy: 0.8903 - val_loss: 0.5905 - learning_rate: 2.0000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1206s\u001b[0m 1s/step - accuracy: 0.9829 - loss: 0.0545 - val_accuracy: 0.8923 - val_loss: 0.6265 - learning_rate: 2.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1243s\u001b[0m 2s/step - accuracy: 0.9862 - loss: 0.0433 - val_accuracy: 0.8931 - val_loss: 0.6177 - learning_rate: 4.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1212s\u001b[0m 1s/step - accuracy: 0.9883 - loss: 0.0390 - val_accuracy: 0.8946 - val_loss: 0.6109 - learning_rate: 4.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1220s\u001b[0m 1s/step - accuracy: 0.9894 - loss: 0.0346 - val_accuracy: 0.8955 - val_loss: 0.6199 - learning_rate: 4.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1217s\u001b[0m 1s/step - accuracy: 0.9892 - loss: 0.0344 - val_accuracy: 0.8951 - val_loss: 0.6189 - learning_rate: 8.0000e-06\n",
      "✅ 'history_plots.png' has been logged to MLflow.\n",
      "\n",
      "==================== Starting Full Evaluation for Logging ====================\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 435ms/step\n",
      "\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "Agaricus lemaneiformis     0.8456    0.9583    0.8984       120\n",
      "              Amaranth     0.9304    0.8699    0.8992       123\n",
      "             Baby Corn     0.9150    0.9396    0.9272       149\n",
      "         Bamboo shoots     0.8529    0.9667    0.9062       120\n",
      "                 Basil     0.8102    0.9328    0.8672       119\n",
      "           Beef Tomato     0.9508    0.9667    0.9587       120\n",
      "           Bell pepper     0.9417    0.9496    0.9456       119\n",
      "   Big Chinese Cabbage     0.7890    0.7167    0.7511       120\n",
      "          Big cucumber     0.8268    0.8750    0.8502       120\n",
      "              Bok Choy     0.8409    0.9250    0.8810       120\n",
      "       Chinese Cabbage     0.9083    0.9083    0.9083       120\n",
      "        Chinese chives     0.8492    0.8917    0.8699       120\n",
      "         Chrysanthemum     0.9009    0.8333    0.8658       120\n",
      "              Cucumber     0.8716    0.7917    0.8297       120\n",
      "          French beans     0.7647    0.8000    0.7820       130\n",
      "                Garlic     0.9384    0.9384    0.9384       146\n",
      "        Garlic sprouts     0.8198    0.7583    0.7879       120\n",
      "        Green Broccoli     0.9521    0.9392    0.9456       148\n",
      "   Green bamboo shoots     0.9669    0.9750    0.9710       120\n",
      "          Green pepper     0.9280    0.9667    0.9469       120\n",
      "                  Kale     0.9300    0.7750    0.8455       120\n",
      "               Lettuce     0.8790    0.9083    0.8934       120\n",
      "                Loofah     0.8136    0.8000    0.8067       120\n",
      "            Lotus root     0.9322    0.9167    0.9244       120\n",
      "         Mainland girl     0.8629    0.8917    0.8770       120\n",
      "   Momordica charantia     0.9554    0.8917    0.9224       120\n",
      "           Mountain Su     0.9113    0.9417    0.9262       120\n",
      "                  Okra     0.9588    0.8900    0.9231       209\n",
      "          Red broccoli     0.9421    0.9500    0.9461       120\n",
      "               Romaine     0.9187    0.9417    0.9300       120\n",
      "              Shallots     0.9060    0.8833    0.8945       120\n",
      "             Sweet Pea     0.8480    0.8833    0.8653       120\n",
      "   Sweet potato leaves     0.8222    0.9250    0.8706       120\n",
      "                  Taro     0.9483    0.9167    0.9322       120\n",
      "           WaWa dishes     0.8870    0.8500    0.8681       120\n",
      "            Water Lily     0.9593    0.9833    0.9712       120\n",
      "         Water spinach     0.8295    0.8560    0.8425       125\n",
      "          White radish     0.9577    0.9282    0.9427       195\n",
      "          Winter melon     0.8605    0.9250    0.8916       120\n",
      "                   Yam     0.8707    0.8417    0.8559       120\n",
      "             asparagus     0.9623    0.8947    0.9273       171\n",
      "               brocoli     0.9732    0.9083    0.9397       120\n",
      "               cabbage     0.8347    0.8417    0.8382       120\n",
      "                carrot     0.9739    0.9333    0.9532       120\n",
      "                celery     0.8966    0.8667    0.8814       120\n",
      "                 chili     0.9328    0.9250    0.9289       120\n",
      "             coriander     0.8306    0.8583    0.8443       120\n",
      "                  corn     0.8438    0.9000    0.8710       120\n",
      "                cowpea     0.8842    0.7000    0.7814       120\n",
      "              eggplant     0.9516    0.9833    0.9672       120\n",
      "                ginger     0.9316    0.9083    0.9198       120\n",
      "           green onion     0.7518    0.8833    0.8123       120\n",
      "                 onion     0.8346    0.9250    0.8775       120\n",
      "                   pea     0.8947    0.8500    0.8718       120\n",
      "                potato     0.8793    0.8500    0.8644       120\n",
      "               pumpkin     0.9402    0.9167    0.9283       120\n",
      "                  rape     0.7642    0.7833    0.7737       120\n",
      "               spinach     0.8966    0.8667    0.8814       120\n",
      "          sweet potato     0.8929    0.8333    0.8621       120\n",
      "              zucchini     0.9098    0.9250    0.9174       120\n",
      "\n",
      "              accuracy                         0.8901      7514\n",
      "             macro avg     0.8896    0.8892    0.8883      7514\n",
      "          weighted avg     0.8919    0.8901    0.8899      7514\n",
      "\n",
      "✅ 'classification_report.txt' has been logged to MLflow.\n",
      "✅ 'confusion_matrix.png' has been logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 11:47:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/19 11:47:48 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'sorted_correct_counts.png' has been logged to MLflow.\n",
      "==================== Full Evaluation Logging Complete ====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 11:48:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Run 4fe9db785c274fabb616b6942d0ee18d 完成。最佳驗證準確率: 0.8955\n",
      "🎉 新的最佳模型! Model: MobileNetV3-Large, Run ID: 4fe9db785c274fabb616b6942d0ee18d, Accuracy: 0.8955\n",
      "💾 最佳模型已更新並儲存為 '1MobileNetV3-Large_0.8955.keras'\n",
      "======================================================================\n",
      "🏁 自動調參完成。\n",
      "🏆 最終最佳模型的 Run ID 為: 4fe9db785c274fabb616b6942d0ee18d\n",
      "🏆 最終最佳驗證準確率為: 0.8955\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 3. 執行主流程 (已更新)\n",
    "\n",
    "# --- 定義路徑 ---\n",
    "train_path = \"dataset_full_en_aug2/train\"\n",
    "validation_path = \"dataset_full_en_aug2/validation\"\n",
    "\n",
    "# --- 啟動自動訓練與調參 ---\n",
    "if __name__ == '__main__':\n",
    "    # 函式內部會處理數據生成器、類別數量和權重計算\n",
    "    train_and_tune(\n",
    "        train_path=train_path,\n",
    "        validation_path=validation_path,\n",
    "        target_accuracy=0.98\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef659344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
