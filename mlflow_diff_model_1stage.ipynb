{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d8ad028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "import visualkeras\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from tensorflow.keras.applications import mobilenet_v3, efficientnet\n",
    "import itertools # ç¢ºä¿ itertools å·²åŒ¯å…¥\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers, layers, models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint \n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70b5b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 1. å»ºç«‹æ¨¡å‹çš„å‡½å¼ (å·²æ›´æ–°ï¼Œæ”¯æ´å…©éšæ®µè¨“ç·´çš„å‡çµæ§åˆ¶)\n",
    "def build_model(model_name, learning_rate, dropout_rate, dense_units, trainable_layers, num_classes, freeze_base_model=False):\n",
    "    \"\"\"\n",
    "    æ ¹æ“šå‚³å…¥çš„è¶…åƒæ•¸å»ºç«‹ä¸¦ç·¨è­¯æŒ‡å®šçš„ Keras æ¨¡å‹ã€‚\n",
    "    *** ä½¿ç”¨ Functional API ä»¥ç¢ºä¿æ¨¡å‹çµæ§‹çš„ç©©å¥æ€§ ***\n",
    "    \"\"\"\n",
    "    input_shape = (224, 224, 3)\n",
    "    \n",
    "    # å®šç¾©æ¨¡å‹è¼¸å…¥\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # æ ¹æ“š model_name é¸æ“‡ä¸¦å»ºç«‹åŸºç¤æ¨¡å‹\n",
    "    if model_name == 'MobileNetV3-Large':\n",
    "        base_model = keras.applications.MobileNetV3Large(\n",
    "            input_shape=input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            # é—œéµï¼šå°‡ base_model çš„è¼¸å…¥èˆ‡æˆ‘å€‘å®šç¾©çš„ `inputs` å¼µé‡é€£æ¥èµ·ä¾†\n",
    "            input_tensor=inputs \n",
    "        )\n",
    "        print(\"âœ… Base model loaded: MobileNetV3-Large\")\n",
    "    elif model_name == 'EfficientNet-B0':\n",
    "        base_model = keras.applications.EfficientNetB0(\n",
    "            input_shape=input_shape,\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            # é—œéµï¼šå°‡ base_model çš„è¼¸å…¥èˆ‡æˆ‘å€‘å®šç¾©çš„ `inputs` å¼µé‡é€£æ¥èµ·ä¾†\n",
    "            input_tensor=inputs\n",
    "        )\n",
    "        print(\"âœ… Base model loaded: EfficientNetB0\")\n",
    "    else:\n",
    "        raise ValueError(f\"ä¸æ”¯æ´çš„æ¨¡å‹åç¨±: {model_name}ã€‚\")\n",
    "        \n",
    "    # --- è¨­å®šåŸºåº•æ¨¡å‹çš„å¯è¨“ç·´æ€§ ---\n",
    "    if freeze_base_model:\n",
    "        base_model.trainable = False\n",
    "        print(\"ğŸ§Š Stage 1: Base model is FROZEN.\")\n",
    "    else:\n",
    "        base_model.trainable = True\n",
    "        if trainable_layers > 0 and trainable_layers < len(base_model.layers):\n",
    "            for layer in base_model.layers[:-trainable_layers]:\n",
    "                layer.trainable = False\n",
    "            print(f\"ğŸ”¥ Stage 2: Fine-tuning. Last {trainable_layers} layers of base model are UNFROZEN.\")\n",
    "        else:\n",
    "            print(\"ğŸ”¥ Stage 2: Fine-tuning. All layers of base model are UNFROZEN.\")\n",
    "\n",
    "    # --- ä½¿ç”¨ Functional API ä¸²æ¥æ¨¡å‹ ---\n",
    "    # å–å¾— base_model çš„è¼¸å‡º\n",
    "    x = base_model.output\n",
    "    # é€£æ¥åˆ°å¾ŒçºŒçš„å±¤\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(dense_units, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(dense_units, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    # è¼¸å‡ºå±¤\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # å»ºç«‹æœ€çµ‚æ¨¡å‹ï¼Œæ˜ç¢ºæŒ‡å®šè¼¸å…¥å’Œè¼¸å‡º\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # ç·¨è­¯æ¨¡å‹ (éœ€è¦ä½¿ç”¨ Adam çš„å¯¦ä¾‹ï¼Œè€Œä¸æ˜¯å­—ä¸² 'Adam')\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b38f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MLflow è¦–è¦ºåŒ–èˆ‡æ—¥èªŒè¨˜éŒ„è¼”åŠ©å‡½å¼ (ç¶­æŒä¸è®Š)\n",
    "\n",
    "def plot_and_log_history(history, filename=\"history_plots.png\"):\n",
    "    \"\"\"\n",
    "    ç¹ªè£½æº–ç¢ºç‡å’Œæå¤±å‡½æ•¸çš„æ­·å²æ›²ç·šï¼Œä¸¦å°‡å…¶å„²å­˜ç‚ºåœ–ç‰‡ï¼Œæœ€å¾Œè¨˜éŒ„åˆ° MLflowã€‚\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # æº–ç¢ºç‡åœ–\n",
    "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.set_title('Accuracy over epochs')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # æå¤±å‡½æ•¸åœ–\n",
    "    ax2.plot(history.history['loss'], label='Train Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Val Loss')\n",
    "    ax2.set_title('Loss over epochs')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # å„²å­˜åœ–ç‰‡ä¸¦é—œé–‰ç¹ªåœ–\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)  # ç¢ºä¿é—œé–‰æ­£ç¢ºçš„ figure\n",
    "    \n",
    "    # å°‡åœ–ç‰‡è¨˜éŒ„åˆ° MLflow\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"âœ… '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def log_confusion_matrix(y_true, y_pred, class_labels, filename=\"confusion_matrix.png\"):\n",
    "    \"\"\" ç¹ªè£½ã€å„²å­˜ä¸¦è¨˜éŒ„æ¨™æº–æ··æ·†çŸ©é™£ \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(18, 14)) # å¢åŠ åœ–ç‰‡å¤§å°ä»¥å®¹ç´æ›´å¤šé¡åˆ¥\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap='Blues')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"âœ… '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def plot_and_log_sorted_confusion_bar(y_true, y_pred, class_labels, filename=\"sorted_correct_counts.png\"):\n",
    "    \"\"\" è¨ˆç®—ã€ç¹ªè£½ä¸¦è¨˜éŒ„ä¸€å€‹é•·æ¢åœ–ï¼Œé¡¯ç¤ºæ¯å€‹é¡åˆ¥çš„æ­£ç¢ºé æ¸¬æ•¸é‡ï¼ˆç”±é«˜åˆ°ä½æ’åºï¼‰ã€‚ \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    correct_counts = np.diag(cm)\n",
    "    \n",
    "    sorted_idx = np.argsort(correct_counts)[::-1]\n",
    "    sorted_counts = correct_counts[sorted_idx]\n",
    "    sorted_labels = np.array(class_labels)[sorted_idx]\n",
    "\n",
    "    plt.figure(figsize=(18, 8)) # å¢åŠ åœ–ç‰‡å¯¬åº¦\n",
    "    plt.bar(range(len(sorted_counts)), sorted_counts, color='lightgreen')\n",
    "    plt.xticks(range(len(sorted_labels)), sorted_labels, rotation=90)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Correctly Predicted Count')\n",
    "    plt.title('Correctly Predicted Count per Class (sorted)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"âœ… '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def evaluate_and_log_all_reports(model, data_generator, class_labels):\n",
    "    \"\"\"\n",
    "    è©•ä¼°æ¨¡å‹ä¸¦è¨˜éŒ„åˆ†é¡å ±å‘Šã€æ··æ·†çŸ©é™£åŠå…¶ä»–åˆ†æåœ–åˆ° MLflowã€‚\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*20 + \" Starting Full Evaluation for Logging \" + \"=\"*20)\n",
    "\n",
    "    # é—œéµï¼šé‡ç½® generator ä»¥ç¢ºä¿é †åºæ­£ç¢º\n",
    "    data_generator.reset()\n",
    "\n",
    "    # 1. æ¨¡å‹é æ¸¬\n",
    "    # ä½¿ç”¨ predict() æ–¹æ³•ï¼Œä¸¦æŒ‡å®š stepsï¼Œå¯ä»¥ç¢ºä¿è™•ç†å®Œæ‰€æœ‰æ¨£æœ¬\n",
    "    predictions = model.predict(data_generator, steps=len(data_generator), verbose=1)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # 2. å–å¾—çœŸå¯¦æ¨™ç±¤\n",
    "    # æ³¨æ„ï¼šgenerator çš„ classes å±¬æ€§åŒ…å«äº†æ‰€æœ‰æ¨£æœ¬çš„çœŸå¯¦æ¨™ç±¤\n",
    "    y_true = data_generator.classes\n",
    "\n",
    "    # ç¢ºä¿é•·åº¦ä¸€è‡´ï¼Œé€™åœ¨ generator batch_size ç„¡æ³•æ•´é™¤ç¸½æ¨£æœ¬æ•¸æ™‚å¾ˆé‡è¦\n",
    "    if len(y_pred) != len(y_true):\n",
    "        print(f\"âš ï¸ y_pred length {len(y_pred)} vs y_true length {len(y_true)}. This is normal if batch_size doesn't divide total samples.\")\n",
    "        # `predict` æœƒè™•ç†å®Œæ‰€æœ‰æ¨£æœ¬ï¼Œæ‰€ä»¥ y_true ä¹Ÿæ‡‰è©²æ˜¯å®Œæ•´çš„\n",
    "        y_true = y_true[:len(y_pred)]\n",
    "\n",
    "    # 3. ç”¢ç”Ÿä¸¦è¨˜éŒ„åˆ†é¡å ±å‘Š\n",
    "    report = classification_report(y_true, y_pred, target_names=class_labels, digits=4, zero_division=0)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    mlflow.log_text(report, \"classification_report.txt\")\n",
    "    print(\"âœ… 'classification_report.txt' has been logged to MLflow.\")\n",
    "\n",
    "    # 4. è¨˜éŒ„æ··æ·†çŸ©é™£\n",
    "    log_confusion_matrix(y_true, y_pred, class_labels)\n",
    "\n",
    "    # 5. è¨˜éŒ„æ’åºå¾Œçš„æ­£ç¢ºé æ¸¬æ•¸é‡é•·æ¢åœ–\n",
    "    plot_and_log_sorted_confusion_bar(y_true, y_pred, class_labels)\n",
    "    \n",
    "    print(\"=\"*20 + \" Full Evaluation Logging Complete \" + \"=\"*20 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ad3f6",
   "metadata": {},
   "source": [
    "### å…©ç¨®æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b30e6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 2. è‡ªå‹•è¨“ç·´èˆ‡èª¿åƒçš„ä¸»å‡½å¼ (å·²æ›´æ–°ç‚ºä½¿ç”¨ preprocess_input)\n",
    "def train_and_tune(train_path, validation_path, target_accuracy):\n",
    "    \"\"\"\n",
    "    è‡ªå‹•åŸ·è¡Œå…©éšæ®µè¨“ç·´å’Œè¶…åƒæ•¸èª¿æ•´ã€‚\n",
    "    ç‚ºæ¯å€‹æ¨¡å‹å‹•æ…‹å‰µå»ºä½¿ç”¨å…¶å°ˆå±¬ preprocess_input çš„æ•¸æ“šç”Ÿæˆå™¨ã€‚\n",
    "    \"\"\"\n",
    "    # å®šç¾©è¶…åƒæ•¸çš„æœå°‹ç©ºé–“\n",
    "    param_space = {\n",
    "        'model_name': [\n",
    "            'MobileNetV3-Large', \n",
    "            # 'EfficientNet-B0'\n",
    "            ],\n",
    "        'learning_rate': [0.001],\n",
    "        'dropout_rate': [0.3],\n",
    "        'dense_units': [256],\n",
    "        'trainable_layers': [80]  # å¯èª¿æ•´çš„å±¤æ•¸\n",
    "    }\n",
    "    \n",
    "    STAGE_1_EPOCHS = 30\n",
    "    STAGE_2_EPOCHS = 50\n",
    "    FINE_TUNE_LR_MULTIPLIER = 0.1\n",
    "    \n",
    "    keys, values = zip(*param_space.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    best_run_id = None\n",
    "\n",
    "    mlflow.set_experiment(\"MobileNetV3 å–®éšæ®µ è³‡æ–™é›†2(60)\")\n",
    "    \n",
    "    for i, params in enumerate(param_combinations):\n",
    "        if best_val_accuracy >= target_accuracy:\n",
    "            print(f\"ğŸ¯ ç›®æ¨™å·²é”æˆ (Accuracy >= {target_accuracy:.2f})ã€‚åœæ­¢æœå°‹ã€‚\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"ğŸš€ Run {i+1}/{len(param_combinations)}: å˜—è©¦åƒæ•¸çµ„åˆ: {params}\")\n",
    "\n",
    "        # --- é—œéµä¿®æ”¹ï¼šæ ¹æ“šæ¨¡å‹åç¨±é¸æ“‡é è™•ç†å‡½å¼ ---\n",
    "        if params['model_name'] == 'MobileNetV3-Large':\n",
    "            preprocessing_function = mobilenet_v3.preprocess_input\n",
    "            print(\"INFO: Using MobileNetV3 preprocess_input.\")\n",
    "        elif params['model_name'] == 'EfficientNet-B0':\n",
    "            preprocessing_function = efficientnet.preprocess_input\n",
    "            print(\"INFO: Using EfficientNet preprocess_input.\")\n",
    "        else:\n",
    "            raise ValueError(f\"æœªçŸ¥çš„æ¨¡å‹: {params['model_name']}\")\n",
    "\n",
    "        # --- åœ¨è¿´åœˆå…§éƒ¨å‰µå»ºæ•¸æ“šç”Ÿæˆå™¨ ---\n",
    "        train_datagen_aug = ImageDataGenerator(\n",
    "            preprocessing_function=preprocessing_function,  # ä½¿ç”¨æŒ‡å®šçš„å‡½å¼\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            brightness_range=[0.9, 1.1],\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        \n",
    "        validation_datagen = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "\n",
    "        train_gen = train_datagen_aug.flow_from_directory(\n",
    "            train_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        val_gen = validation_datagen.flow_from_directory(\n",
    "            validation_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        # å¾ç”Ÿæˆå™¨ç²å–æ•¸æ“šé›†ä¿¡æ¯\n",
    "        num_classes = train_gen.num_classes\n",
    "        class_labels = list(train_gen.class_indices.keys())\n",
    "\n",
    "        # å„²å­˜é¡åˆ¥åç¨±åˆ° classes.csv\n",
    "        with open('classes_new.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for cls in class_labels:\n",
    "                writer.writerow([cls])\n",
    "        \n",
    "        # è¨ˆç®— class_weight\n",
    "        class_indices = np.unique(train_gen.classes)\n",
    "        class_weights_array = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=class_indices,\n",
    "            y=train_gen.classes\n",
    "        )\n",
    "        class_weight = dict(zip(class_indices, class_weights_array))\n",
    "\n",
    "        # --- è¨“ç·´æµç¨‹ï¼ˆèˆ‡ä¹‹å‰ç›¸åŒï¼‰ ---\n",
    "        with mlflow.start_run(run_name=f\"{params['model_name']}_run_{i+1}\") as run:\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-9),\n",
    "                ModelCheckpoint(\"model_checkpoint.keras\", monitor=\"val_loss\", save_best_only=True)\n",
    "            ]\n",
    "            \n",
    "            # STAGE 1: è¨“ç·´åˆ†é¡é ­\n",
    "            # print(\"\\n\" + \"-\" * 20 + \" STAGE 1: Feature Extraction \" + \"-\" * 20)\n",
    "            model = build_model(\n",
    "                **params, \n",
    "                num_classes=num_classes, \n",
    "                freeze_base_model=False\n",
    "                )\n",
    "            \n",
    "            history_stage1 = model.fit(\n",
    "                train_gen, \n",
    "                epochs=STAGE_1_EPOCHS, \n",
    "                validation_data=val_gen, \n",
    "                callbacks=callbacks, \n",
    "                class_weight=class_weight, \n",
    "                verbose=1\n",
    "                )\n",
    "            \n",
    "            \n",
    "            # MLflow è¨˜éŒ„\n",
    "            val_accuracy = max(history_stage1.history['val_accuracy'])\n",
    "            mlflow.log_metric(\"best_val_accuracy\", val_accuracy)\n",
    "            \n",
    "            plot_and_log_history(history_stage1)\n",
    "            evaluate_and_log_all_reports(model, val_gen, class_labels)\n",
    "            mlflow.keras.log_model(model, \"model\")\n",
    "            \n",
    "            print(f\"âœ”ï¸ Run {run.info.run_id} å®Œæˆã€‚æœ€ä½³é©—è­‰æº–ç¢ºç‡: {val_accuracy:.4f}\")\n",
    "            \n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                best_run_id = run.info.run_id\n",
    "                print(f\"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! Model: {params['model_name']}, Run ID: {best_run_id}, Accuracy: {best_val_accuracy:.4f}\")\n",
    "                model.save(f'checkpoints/bestmodel/{i+1}{params['model_name']}_{best_val_accuracy:.4f}.keras')\n",
    "                print(f\"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²æ›´æ–°ä¸¦å„²å­˜ç‚º '{i+1}{params['model_name']}_{best_val_accuracy:.4f}.keras'\")\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"ğŸ è‡ªå‹•èª¿åƒå®Œæˆã€‚\")\n",
    "    if best_run_id:\n",
    "        print(f\"ğŸ† æœ€çµ‚æœ€ä½³æ¨¡å‹çš„ Run ID ç‚º: {best_run_id}\")\n",
    "        print(f\"ğŸ† æœ€çµ‚æœ€ä½³é©—è­‰æº–ç¢ºç‡ç‚º: {best_val_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(\"âŒ æœªèƒ½æˆåŠŸè¨“ç·´ä»»ä½•æ¨¡å‹ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e09c9c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸš€ Run 1/1: å˜—è©¦åƒæ•¸çµ„åˆ: {'model_name': 'MobileNetV3-Large', 'learning_rate': 0.001, 'dropout_rate': 0.3, 'dense_units': 256, 'trainable_layers': 80}\n",
      "INFO: Using MobileNetV3 preprocess_input.\n",
      "Found 26307 images belonging to 60 classes.\n",
      "Found 7514 images belonging to 60 classes.\n",
      "âœ… Base model loaded: MobileNetV3-Large\n",
      "ğŸ”¥ Stage 2: Fine-tuning. Last 80 layers of base model are UNFROZEN.\n",
      "Epoch 1/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1250s\u001b[0m 1s/step - accuracy: 0.5087 - loss: 1.8238 - val_accuracy: 0.3352 - val_loss: 22.3606 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1338s\u001b[0m 2s/step - accuracy: 0.7175 - loss: 0.9922 - val_accuracy: 0.4138 - val_loss: 24.4261 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1339s\u001b[0m 2s/step - accuracy: 0.7731 - loss: 0.7967 - val_accuracy: 0.5426 - val_loss: 7.7709 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1249s\u001b[0m 2s/step - accuracy: 0.8045 - loss: 0.6913 - val_accuracy: 0.5293 - val_loss: 9.5688 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1332s\u001b[0m 2s/step - accuracy: 0.8249 - loss: 0.6086 - val_accuracy: 0.6699 - val_loss: 12.8158 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1331s\u001b[0m 2s/step - accuracy: 0.8419 - loss: 0.5511 - val_accuracy: 0.6163 - val_loss: 3.9725 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1202s\u001b[0m 1s/step - accuracy: 0.8564 - loss: 0.5013 - val_accuracy: 0.7441 - val_loss: 1.4543 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1367s\u001b[0m 2s/step - accuracy: 0.8680 - loss: 0.4567 - val_accuracy: 0.6805 - val_loss: 2.2000 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1518s\u001b[0m 2s/step - accuracy: 0.8830 - loss: 0.4092 - val_accuracy: 0.7241 - val_loss: 2.5345 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1476s\u001b[0m 2s/step - accuracy: 0.8860 - loss: 0.3872 - val_accuracy: 0.7529 - val_loss: 1.1142 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1500s\u001b[0m 2s/step - accuracy: 0.8927 - loss: 0.3762 - val_accuracy: 0.7785 - val_loss: 0.9895 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1492s\u001b[0m 2s/step - accuracy: 0.9020 - loss: 0.3422 - val_accuracy: 0.7723 - val_loss: 0.9971 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1493s\u001b[0m 2s/step - accuracy: 0.9053 - loss: 0.3328 - val_accuracy: 0.7899 - val_loss: 0.9376 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1499s\u001b[0m 2s/step - accuracy: 0.9100 - loss: 0.3129 - val_accuracy: 0.7129 - val_loss: 1.3085 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1526s\u001b[0m 2s/step - accuracy: 0.9171 - loss: 0.2934 - val_accuracy: 0.8094 - val_loss: 0.9145 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1496s\u001b[0m 2s/step - accuracy: 0.9170 - loss: 0.2894 - val_accuracy: 0.7958 - val_loss: 1.0534 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1488s\u001b[0m 2s/step - accuracy: 0.9211 - loss: 0.2821 - val_accuracy: 0.7812 - val_loss: 1.0030 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1520s\u001b[0m 2s/step - accuracy: 0.9271 - loss: 0.2523 - val_accuracy: 0.8324 - val_loss: 0.7276 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1729s\u001b[0m 2s/step - accuracy: 0.9275 - loss: 0.2492 - val_accuracy: 0.8331 - val_loss: 0.7680 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1726s\u001b[0m 2s/step - accuracy: 0.9306 - loss: 0.2406 - val_accuracy: 0.8076 - val_loss: 0.8753 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1767s\u001b[0m 2s/step - accuracy: 0.9328 - loss: 0.2354 - val_accuracy: 0.8311 - val_loss: 0.8597 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1711s\u001b[0m 2s/step - accuracy: 0.9648 - loss: 0.1159 - val_accuracy: 0.8836 - val_loss: 0.5470 - learning_rate: 2.0000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1212s\u001b[0m 1s/step - accuracy: 0.9767 - loss: 0.0809 - val_accuracy: 0.8901 - val_loss: 0.5371 - learning_rate: 2.0000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1214s\u001b[0m 1s/step - accuracy: 0.9795 - loss: 0.0658 - val_accuracy: 0.8862 - val_loss: 0.5938 - learning_rate: 2.0000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1214s\u001b[0m 1s/step - accuracy: 0.9805 - loss: 0.0614 - val_accuracy: 0.8903 - val_loss: 0.5905 - learning_rate: 2.0000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1206s\u001b[0m 1s/step - accuracy: 0.9829 - loss: 0.0545 - val_accuracy: 0.8923 - val_loss: 0.6265 - learning_rate: 2.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1243s\u001b[0m 2s/step - accuracy: 0.9862 - loss: 0.0433 - val_accuracy: 0.8931 - val_loss: 0.6177 - learning_rate: 4.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1212s\u001b[0m 1s/step - accuracy: 0.9883 - loss: 0.0390 - val_accuracy: 0.8946 - val_loss: 0.6109 - learning_rate: 4.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1220s\u001b[0m 1s/step - accuracy: 0.9894 - loss: 0.0346 - val_accuracy: 0.8955 - val_loss: 0.6199 - learning_rate: 4.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m823/823\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1217s\u001b[0m 1s/step - accuracy: 0.9892 - loss: 0.0344 - val_accuracy: 0.8951 - val_loss: 0.6189 - learning_rate: 8.0000e-06\n",
      "âœ… 'history_plots.png' has been logged to MLflow.\n",
      "\n",
      "==================== Starting Full Evaluation for Logging ====================\n",
      "\u001b[1m235/235\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 435ms/step\n",
      "\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "Agaricus lemaneiformis     0.8456    0.9583    0.8984       120\n",
      "              Amaranth     0.9304    0.8699    0.8992       123\n",
      "             Baby Corn     0.9150    0.9396    0.9272       149\n",
      "         Bamboo shoots     0.8529    0.9667    0.9062       120\n",
      "                 Basil     0.8102    0.9328    0.8672       119\n",
      "           Beef Tomato     0.9508    0.9667    0.9587       120\n",
      "           Bell pepper     0.9417    0.9496    0.9456       119\n",
      "   Big Chinese Cabbage     0.7890    0.7167    0.7511       120\n",
      "          Big cucumber     0.8268    0.8750    0.8502       120\n",
      "              Bok Choy     0.8409    0.9250    0.8810       120\n",
      "       Chinese Cabbage     0.9083    0.9083    0.9083       120\n",
      "        Chinese chives     0.8492    0.8917    0.8699       120\n",
      "         Chrysanthemum     0.9009    0.8333    0.8658       120\n",
      "              Cucumber     0.8716    0.7917    0.8297       120\n",
      "          French beans     0.7647    0.8000    0.7820       130\n",
      "                Garlic     0.9384    0.9384    0.9384       146\n",
      "        Garlic sprouts     0.8198    0.7583    0.7879       120\n",
      "        Green Broccoli     0.9521    0.9392    0.9456       148\n",
      "   Green bamboo shoots     0.9669    0.9750    0.9710       120\n",
      "          Green pepper     0.9280    0.9667    0.9469       120\n",
      "                  Kale     0.9300    0.7750    0.8455       120\n",
      "               Lettuce     0.8790    0.9083    0.8934       120\n",
      "                Loofah     0.8136    0.8000    0.8067       120\n",
      "            Lotus root     0.9322    0.9167    0.9244       120\n",
      "         Mainland girl     0.8629    0.8917    0.8770       120\n",
      "   Momordica charantia     0.9554    0.8917    0.9224       120\n",
      "           Mountain Su     0.9113    0.9417    0.9262       120\n",
      "                  Okra     0.9588    0.8900    0.9231       209\n",
      "          Red broccoli     0.9421    0.9500    0.9461       120\n",
      "               Romaine     0.9187    0.9417    0.9300       120\n",
      "              Shallots     0.9060    0.8833    0.8945       120\n",
      "             Sweet Pea     0.8480    0.8833    0.8653       120\n",
      "   Sweet potato leaves     0.8222    0.9250    0.8706       120\n",
      "                  Taro     0.9483    0.9167    0.9322       120\n",
      "           WaWa dishes     0.8870    0.8500    0.8681       120\n",
      "            Water Lily     0.9593    0.9833    0.9712       120\n",
      "         Water spinach     0.8295    0.8560    0.8425       125\n",
      "          White radish     0.9577    0.9282    0.9427       195\n",
      "          Winter melon     0.8605    0.9250    0.8916       120\n",
      "                   Yam     0.8707    0.8417    0.8559       120\n",
      "             asparagus     0.9623    0.8947    0.9273       171\n",
      "               brocoli     0.9732    0.9083    0.9397       120\n",
      "               cabbage     0.8347    0.8417    0.8382       120\n",
      "                carrot     0.9739    0.9333    0.9532       120\n",
      "                celery     0.8966    0.8667    0.8814       120\n",
      "                 chili     0.9328    0.9250    0.9289       120\n",
      "             coriander     0.8306    0.8583    0.8443       120\n",
      "                  corn     0.8438    0.9000    0.8710       120\n",
      "                cowpea     0.8842    0.7000    0.7814       120\n",
      "              eggplant     0.9516    0.9833    0.9672       120\n",
      "                ginger     0.9316    0.9083    0.9198       120\n",
      "           green onion     0.7518    0.8833    0.8123       120\n",
      "                 onion     0.8346    0.9250    0.8775       120\n",
      "                   pea     0.8947    0.8500    0.8718       120\n",
      "                potato     0.8793    0.8500    0.8644       120\n",
      "               pumpkin     0.9402    0.9167    0.9283       120\n",
      "                  rape     0.7642    0.7833    0.7737       120\n",
      "               spinach     0.8966    0.8667    0.8814       120\n",
      "          sweet potato     0.8929    0.8333    0.8621       120\n",
      "              zucchini     0.9098    0.9250    0.9174       120\n",
      "\n",
      "              accuracy                         0.8901      7514\n",
      "             macro avg     0.8896    0.8892    0.8883      7514\n",
      "          weighted avg     0.8919    0.8901    0.8899      7514\n",
      "\n",
      "âœ… 'classification_report.txt' has been logged to MLflow.\n",
      "âœ… 'confusion_matrix.png' has been logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 11:47:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/19 11:47:48 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 'sorted_correct_counts.png' has been logged to MLflow.\n",
      "==================== Full Evaluation Logging Complete ====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 11:48:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ”ï¸ Run 4fe9db785c274fabb616b6942d0ee18d å®Œæˆã€‚æœ€ä½³é©—è­‰æº–ç¢ºç‡: 0.8955\n",
      "ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹! Model: MobileNetV3-Large, Run ID: 4fe9db785c274fabb616b6942d0ee18d, Accuracy: 0.8955\n",
      "ğŸ’¾ æœ€ä½³æ¨¡å‹å·²æ›´æ–°ä¸¦å„²å­˜ç‚º '1MobileNetV3-Large_0.8955.keras'\n",
      "======================================================================\n",
      "ğŸ è‡ªå‹•èª¿åƒå®Œæˆã€‚\n",
      "ğŸ† æœ€çµ‚æœ€ä½³æ¨¡å‹çš„ Run ID ç‚º: 4fe9db785c274fabb616b6942d0ee18d\n",
      "ğŸ† æœ€çµ‚æœ€ä½³é©—è­‰æº–ç¢ºç‡ç‚º: 0.8955\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 3. åŸ·è¡Œä¸»æµç¨‹ (å·²æ›´æ–°)\n",
    "\n",
    "# --- å®šç¾©è·¯å¾‘ ---\n",
    "train_path = \"dataset_full_en_aug2/train\"\n",
    "validation_path = \"dataset_full_en_aug2/validation\"\n",
    "\n",
    "# --- å•Ÿå‹•è‡ªå‹•è¨“ç·´èˆ‡èª¿åƒ ---\n",
    "if __name__ == '__main__':\n",
    "    # å‡½å¼å…§éƒ¨æœƒè™•ç†æ•¸æ“šç”Ÿæˆå™¨ã€é¡åˆ¥æ•¸é‡å’Œæ¬Šé‡è¨ˆç®—\n",
    "    train_and_tune(\n",
    "        train_path=train_path,\n",
    "        validation_path=validation_path,\n",
    "        target_accuracy=0.98\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef659344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
