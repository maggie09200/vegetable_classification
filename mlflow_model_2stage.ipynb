{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4010c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "import visualkeras\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers, layers, models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint \n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c087ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 1. 建立模型的函式\n",
    "def build_model(learning_rate, dropout_rate, dense_units, trainable_layers, num_classes):\n",
    "    \"\"\"\n",
    "    根據傳入的超參數建立 MobileNetV2 模型。\n",
    "\n",
    "    參數:\n",
    "    - learning_rate (float): 學習率\n",
    "    - dropout_rate (float): Dropout 比率\n",
    "    - dense_units (int): 全連接層的神經元數量\n",
    "    - trainable_layers (int): MobileNetV2 中可訓練的層數 (從後往前算)\n",
    "    - num_classes (int): 分類的類別總數\n",
    "    \n",
    "    返回:\n",
    "    - model: 已編譯的 Keras 模型\n",
    "    \"\"\"\n",
    "    # 建立基礎模型 MobileNetV2\n",
    "    base_model = keras.applications.MobileNetV2(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # 設定可訓練的層數\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-trainable_layers]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # 建立序列模型\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(dense_units, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(dense_units, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # 編譯模型\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6a0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# 1. MLflow 視覺化與日誌記錄輔助函式\n",
    "# ===================================================================\n",
    "\n",
    "def plot_and_log_history(history, filename=\"history_plots.png\"):\n",
    "    \"\"\"\n",
    "    繪製準確率和損失函數的歷史曲線，並將其儲存為圖片，最後記錄到 MLflow。\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 準確率圖\n",
    "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.set_title('Accuracy over epochs')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # 損失函數圖\n",
    "    ax2.plot(history.history['loss'], label='Train Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Val Loss')\n",
    "    ax2.set_title('Loss over epochs')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # 儲存圖片並關閉繪圖\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)  # 確保關閉正確的 figure\n",
    "    \n",
    "    # 將圖片記錄到 MLflow\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"✅ '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def log_confusion_matrix(y_true, y_pred, class_labels, filename=\"confusion_matrix.png\"):\n",
    "    \"\"\" 繪製、儲存並記錄標準混淆矩陣 \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(18, 14)) # 增加圖片大小以容納更多類別\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap='Blues')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"✅ '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def plot_and_log_sorted_confusion_bar(y_true, y_pred, class_labels, filename=\"sorted_correct_counts.png\"):\n",
    "    \"\"\" 計算、繪製並記錄一個長條圖，顯示每個類別的正確預測數量（由高到低排序）。 \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    correct_counts = np.diag(cm)\n",
    "    \n",
    "    sorted_idx = np.argsort(correct_counts)[::-1]\n",
    "    sorted_counts = correct_counts[sorted_idx]\n",
    "    sorted_labels = np.array(class_labels)[sorted_idx]\n",
    "\n",
    "    plt.figure(figsize=(18, 8)) # 增加圖片寬度\n",
    "    plt.bar(range(len(sorted_counts)), sorted_counts, color='lightgreen')\n",
    "    plt.xticks(range(len(sorted_labels)), sorted_labels, rotation=90)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Correctly Predicted Count')\n",
    "    plt.title('Correctly Predicted Count per Class (sorted)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"✅ '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def evaluate_and_log_all_reports(model, data_generator, class_labels):\n",
    "    \"\"\"\n",
    "    評估模型並記錄分類報告、混淆矩陣及其他分析圖到 MLflow。\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*20 + \" Starting Full Evaluation for Logging \" + \"=\"*20)\n",
    "\n",
    "    # 關鍵：重置 generator 以確保順序正確\n",
    "    data_generator.reset()\n",
    "\n",
    "    # 1. 模型預測\n",
    "    # 使用 predict() 方法，並指定 steps，可以確保處理完所有樣本\n",
    "    predictions = model.predict(data_generator, steps=len(data_generator), verbose=1)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # 2. 取得真實標籤\n",
    "    # 注意：generator 的 classes 屬性包含了所有樣本的真實標籤\n",
    "    y_true = data_generator.classes\n",
    "\n",
    "    # 確保長度一致，這在 generator batch_size 無法整除總樣本數時很重要\n",
    "    if len(y_pred) != len(y_true):\n",
    "        print(f\"⚠️ y_pred length {len(y_pred)} vs y_true length {len(y_true)}. This is normal if batch_size doesn't divide total samples.\")\n",
    "        # `predict` 會處理完所有樣本，所以 y_true 也應該是完整的\n",
    "        y_true = y_true[:len(y_pred)]\n",
    "\n",
    "    # 3. 產生並記錄分類報告\n",
    "    report = classification_report(y_true, y_pred, target_names=class_labels, digits=4, zero_division=0)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    mlflow.log_text(report, \"classification_report.txt\")\n",
    "    print(\"✅ 'classification_report.txt' has been logged to MLflow.\")\n",
    "\n",
    "    # 4. 記錄混淆矩陣\n",
    "    log_confusion_matrix(y_true, y_pred, class_labels)\n",
    "\n",
    "    # 5. 記錄排序後的正確預測數量長條圖\n",
    "    plot_and_log_sorted_confusion_bar(y_true, y_pred, class_labels)\n",
    "    \n",
    "    print(\"=\"*20 + \" Full Evaluation Logging Complete \" + \"=\"*20 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb2b42",
   "metadata": {},
   "source": [
    "### 單階段訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21242e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 2. 自動訓練與調參的主函式 (已更新)\n",
    "import itertools\n",
    "\n",
    "def train_and_tune(train_gen, val_gen, class_labels, class_weight, num_classes, target_accuracy=0.9):\n",
    "    \"\"\"\n",
    "    自動訓練和調整超參數，直到驗證準確率達到目標。\n",
    "    使用 MLflow 自動記錄參數、指標、圖表和模型。\n",
    "    \"\"\"\n",
    "    # 定義超參數的搜尋空間\n",
    "    param_space = {\n",
    "        'learning_rate': [0.0001],\n",
    "        'dropout_rate': [0.5],\n",
    "        'dense_units': [256],\n",
    "        'trainable_layers': [60] # 從 MobileNetV2 的後面開始訓練的層數\n",
    "    }\n",
    "    \n",
    "    keys, values = zip(*param_space.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    best_model = None\n",
    "    best_run_id = None\n",
    "\n",
    "    mlflow.set_experiment(\"MobileNetV2 mixup 資料集3訓練\")\n",
    "    \n",
    "    for i, params in enumerate(param_combinations):\n",
    "        if best_val_accuracy >= target_accuracy:\n",
    "            print(f\"🎯 目標已達成 (Accuracy >= {target_accuracy:.2f})。停止搜尋。\")\n",
    "            break\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"🚀 Run {i+1}/{len(param_combinations)}: 嘗試參數組合: {params}\")\n",
    "\n",
    "        with mlflow.start_run() as run:\n",
    "            # 記錄超參數\n",
    "            mlflow.log_params(params)\n",
    "            \n",
    "            # 建立並編譯模型\n",
    "            model = build_model(num_classes=num_classes, **params)\n",
    "            \n",
    "            # 設定回呼函式\n",
    "            early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-8)\n",
    "            checkpoint = tf.keras.callbacks.ModelCheckpoint(\"model_checkpoint.keras\", monitor=\"val_loss\", save_best_only=True)\n",
    "            \n",
    "            # 模型訓練\n",
    "            history = model.fit(\n",
    "                train_gen,\n",
    "                epochs=30,\n",
    "                validation_data=val_gen,\n",
    "                class_weight=class_weight,\n",
    "                callbacks=[early_stop, reduce_lr, checkpoint],\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # === MLflow 記錄區 ===\n",
    "            \n",
    "            # 1. 記錄主要指標\n",
    "            val_accuracy = max(history.history['val_accuracy'])\n",
    "            mlflow.log_metric(\"best_val_accuracy\", val_accuracy)\n",
    "            mlflow.log_metric(\"final_train_accuracy\", history.history['accuracy'][-1])\n",
    "            mlflow.log_metric(\"stopped_epoch\", len(history.history['val_accuracy']))\n",
    "\n",
    "            # 2. 記錄訓練歷史圖表\n",
    "            plot_and_log_history(history)\n",
    "            \n",
    "            # 3. 記錄完整的評估報告 (混淆矩陣, 分類報告等)\n",
    "            # 使用訓練好的模型 (EarlyStopping 會自動還原最佳權重)\n",
    "            evaluate_and_log_all_reports(model, val_gen, class_labels)\n",
    "            \n",
    "            # 4. 記錄模型\n",
    "            mlflow.keras.log_model(model, \"model\", signature=None) # signature=False 可以加快儲存速度\n",
    "            \n",
    "            print(f\"✔️ Run {run.info.run_id} 完成。最佳驗證準確率: {val_accuracy:.4f}\")\n",
    "            \n",
    "            # 更新全局最佳模型\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                best_model = model\n",
    "                best_run_id = run.info.run_id\n",
    "                print(f\"🎉 新的最佳模型! Run ID: {best_run_id}, Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🏁 自動調參完成。\")\n",
    "    if best_model:\n",
    "        print(f\"🏆 最終最佳模型的 Run ID 為: {best_run_id}\")\n",
    "        print(f\"🏆 最終最佳驗證準確率為: {best_val_accuracy:.4f}\")\n",
    "        best_model.save('best_tuned_model.h5')\n",
    "        print(\"💾 最佳模型已儲存為 'best_tuned_model.h5'\")\n",
    "    else:\n",
    "        print(\"❌ 未能成功訓練任何模型。\")\n",
    "        \n",
    "    return best_model, best_val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f4eebf",
   "metadata": {},
   "source": [
    "### 2階段訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0898cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 2. 自動訓練與調參的主函式 (全面優化版)\n",
    "def train_and_tune(train_gen, val_gen, class_labels, class_weight, num_classes, target_accuracy=0.9):\n",
    "    \"\"\"\n",
    "    自動執行兩階段訓練和超參數調整。\n",
    "    實作了多項遷移學習最佳實踐。\n",
    "    \"\"\"\n",
    "    param_space = {\n",
    "        'learning_rate': [0.0001],\n",
    "        'dropout_rate': [0.5],\n",
    "        'dense_units': [256],\n",
    "        'trainable_layers': [60] \n",
    "    }\n",
    "    \n",
    "    STAGE_1_EPOCHS = 30\n",
    "    STAGE_2_EPOCHS = 50\n",
    "    FINE_TUNE_LR_MULTIPLIER = 0.1\n",
    "    \n",
    "    keys, values = zip(*param_space.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    best_run_id = None\n",
    "\n",
    "    mlflow.set_experiment(\"MobileNetV2新2階段 48種 資料夾3\")\n",
    "    \n",
    "    for i, params in enumerate(param_combinations):\n",
    "\n",
    "        if best_val_accuracy >= target_accuracy:\n",
    "            print(f\"🎯 目標已達成 (Accuracy >= {target_accuracy:.2f})。停止搜尋。\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"🚀 Run {i+1}/{len(param_combinations)}: 嘗試參數組合: {params}\")\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"_run_{i+1}\") as run:\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            # STAGE 1: Feature Extraction\n",
    "            print(\"\\n\" + \"-\" * 20 + \" STAGE 1: Feature Extraction \" + \"-\" * 20)\n",
    "            \n",
    "            # ### 優化 1：接收 model 和 base_model ###\n",
    "            model, base_model = build_model(\n",
    "                **params, num_classes=num_classes, freeze_base_model=True\n",
    "            )\n",
    "            \n",
    "            history_stage1 = model.fit(\n",
    "                train_gen, epochs=STAGE_1_EPOCHS, validation_data=val_gen,\n",
    "                callbacks=[EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)],\n",
    "                class_weight=class_weight, verbose=1\n",
    "            )\n",
    "            \n",
    "            # STAGE 2: Fine-Tuning\n",
    "            print(\"\\n\" + \"-\" * 20 + \" STAGE 2: Fine-Tuning \" + \"-\" * 20)\n",
    "\n",
    "            # --- 直接在現有 model 物件上操作 ---\n",
    "            base_model.trainable = True\n",
    "            \n",
    "            trainable_layers_count = params['trainable_layers']\n",
    "            if trainable_layers_count > 0 and trainable_layers_count < len(base_model.layers):\n",
    "                print(f\"🔥 Fine-tuning: Unfreezing the last {trainable_layers_count} layers.\")\n",
    "                for layer in base_model.layers[:-trainable_layers_count]:\n",
    "                    layer.trainable = False\n",
    "            else:\n",
    "                print(\"🔥 Fine-tuning: Unfreezing all base model layers.\")\n",
    "            \n",
    "            # ### 優化 3a：在微調時凍結 BatchNormalization 層 ###\n",
    "            for layer in base_model.layers:\n",
    "                if isinstance(layer, layers.BatchNormalization):\n",
    "                    layer.trainable = False\n",
    "            print(\"🧊 All BatchNormalization layers in the base model have been frozen.\")\n",
    "\n",
    "            # 用更低的學習率重新編譯模型\n",
    "            fine_tune_lr = params['learning_rate'] * FINE_TUNE_LR_MULTIPLIER\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_lr),\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            callbacks_stage2 = [\n",
    "                EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-9),\n",
    "                ModelCheckpoint(\"model_checkpoint.keras\", monitor=\"val_loss\", save_best_only=True)\n",
    "            ]\n",
    "            history_stage2 = model.fit(\n",
    "                train_gen, epochs=STAGE_2_EPOCHS, validation_data=val_gen,\n",
    "                class_weight=class_weight, callbacks=callbacks_stage2, verbose=1\n",
    "            )\n",
    "            \n",
    "            # --- MLflow 記錄 ---\n",
    "            full_history = {}\n",
    "            for key in history_stage1.history.keys():\n",
    "                full_history[key] = history_stage1.history[key] + history_stage2.history[key]\n",
    "            \n",
    "            # ### 優化 3b：計算整個訓練過程中的最佳驗證準確率 ###\n",
    "            # 確保 history 字典不是空的\n",
    "            best_s1_acc = max(history_stage1.history.get('val_accuracy', [0]))\n",
    "            best_s2_acc = max(history_stage2.history.get('val_accuracy', [0]))\n",
    "            current_run_best_val_accuracy = max(best_s1_acc, best_s2_acc)\n",
    "            \n",
    "            mlflow.log_metric(\"best_val_accuracy\", current_run_best_val_accuracy)\n",
    "            \n",
    "            plot_and_log_history(type('History', (), {'history': full_history})())\n",
    "            evaluate_and_log_all_reports(model, val_gen, class_labels)\n",
    "            mlflow.keras.log_model(model, \"model\")\n",
    "            \n",
    "            print(f\"✔️ Run {run.info.run_id} 完成。本輪最佳驗證準確率: {current_run_best_val_accuracy:.4f}\")\n",
    "            \n",
    "            if current_run_best_val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = current_run_best_val_accuracy\n",
    "                best_run_id = run.info.run_id\n",
    "                print(f\"🎉 新的最佳模型! Model: {params['model_name']}, Run ID: {best_run_id}, Accuracy: {best_val_accuracy:.4f}\")\n",
    "                model.save(f'checkpoints/bestmodel/{i+1}{params['model_name']}_{best_val_accuracy:.4f}.keras')\n",
    "                print(f\"💾 最佳模型已更新並儲存為 '{i+1}{params['model_name']}_{best_val_accuracy:.4f}.keras'\")\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"🏁 自動調參完成。\")\n",
    "    if best_run_id:\n",
    "        print(f\"🏆 最終最佳模型的 Run ID 為: {best_run_id}\")\n",
    "        print(f\"🏆 最終最佳驗證準確率為: {best_val_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(\"❌ 未能成功訓練任何模型。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09adec77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21859 images belonging to 50 classes.\n",
      "Found 6241 images belonging to 50 classes.\n",
      "\n",
      "======================================================================\n",
      "🚀 Run 1/1: 嘗試參數組合: {'learning_rate': 0.0001, 'dropout_rate': 0.5, 'dense_units': 256, 'trainable_layers': 60}\n",
      "\n",
      "-------------------- STAGE 1: Feature Extraction --------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "build_model() got an unexpected keyword argument 'freeze_base_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# --- 啟動自動訓練與調參 ---\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# 將所有需要的參數傳入\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     best_model, best_accuracy = \u001b[43mtrain_and_tune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_generator_aug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weight_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_accuracy\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.99\u001b[39;49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mtrain_and_tune\u001b[39m\u001b[34m(train_gen, val_gen, class_labels, class_weight, num_classes, target_accuracy)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m20\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m STAGE 1: Feature Extraction \u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m20\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# ### 優化 1：接收 model 和 base_model ###\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m model, base_model = \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreeze_base_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     45\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m history_stage1 = model.fit(\n\u001b[32m     48\u001b[39m     train_gen, epochs=STAGE_1_EPOCHS, validation_data=val_gen,\n\u001b[32m     49\u001b[39m     callbacks=[EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m8\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)],\n\u001b[32m     50\u001b[39m     class_weight=class_weight, verbose=\u001b[32m1\u001b[39m\n\u001b[32m     51\u001b[39m )\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# STAGE 2: Fine-Tuning\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: build_model() got an unexpected keyword argument 'freeze_base_model'"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 3. 執行主流程 (已更新)\n",
    "\n",
    "# --- 資料準備 ---\n",
    "train_path = \"dataset_full_en_aug3/train\"\n",
    "validation_path = \"dataset_full_en_aug3/validation\"\n",
    "num_classes = len(os.listdir(train_path))\n",
    "\n",
    "train_datagen_aug = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator_aug = train_datagen_aug.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True # 訓練集需要 shuffle\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False # 驗證/測試集絕不能 shuffle，以確保標籤順序正確\n",
    ")\n",
    "\n",
    "\n",
    "# 從 generator 中獲取類別名稱和索引的對應關係\n",
    "class_labels = list(train_generator_aug.class_indices.keys())\n",
    "\n",
    "# 計算 class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_indices = np.unique(train_generator_aug.classes)\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=class_indices,\n",
    "    y=train_generator_aug.classes\n",
    ")\n",
    "class_weight_dict = dict(zip(class_indices, class_weights_array))\n",
    "\n",
    "\n",
    "# --- 啟動自動訓練與調參 ---\n",
    "if __name__ == '__main__':\n",
    "    # 將所有需要的參數傳入\n",
    "    best_model, best_accuracy = train_and_tune(\n",
    "        train_gen=train_generator_aug,\n",
    "        val_gen=validation_generator,\n",
    "        class_labels=class_labels,\n",
    "        class_weight=class_weight_dict,\n",
    "        num_classes=num_classes,\n",
    "        target_accuracy=0.99\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f26924",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbest_model\u001b[49m.save(\u001b[33m'\u001b[39m\u001b[33mmodel_mnV2(best).keras\u001b[39m\u001b[33m'\u001b[39m) \n",
      "\u001b[31mNameError\u001b[39m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_model.save('model_mnV2(best).keras') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
