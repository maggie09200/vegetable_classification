{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8ad028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "from PIL import Image \n",
    "from pathlib import Path\n",
    "import visualkeras\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from tensorflow.keras.applications import mobilenet_v3, efficientnet\n",
    "import itertools # 確保 itertools 已匯入\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers, layers, models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint \n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# from keras.optimizers import Adam\n",
    "# from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 1. 建立模型的函式 \n",
    "def build_model(model_name, learning_rate, dropout_rate, dense_units, trainable_layers, num_classes, freeze_base_model=False):\n",
    "    \"\"\"\n",
    "    根據傳入的超參數建立並編譯指定的 Keras 模型。\n",
    "    *** 使用 Functional API 以確保模型結構的穩健性 ***\n",
    "    \"\"\"\n",
    "    input_shape = (224, 224, 3)\n",
    "    \n",
    "    # 定義模型輸入\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # 根據 model_name 選擇並建立基礎模型\n",
    "    if model_name == 'MobileNetV3-Large':\n",
    "        base_model = keras.applications.MobileNetV3Large(\n",
    "            input_shape=(224, 224, 3),\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            # 關鍵：將 base_model 的輸入與我們定義的 `inputs` 張量連接起來\n",
    "            input_tensor=inputs \n",
    "        )\n",
    "        print(\"✅ Base model loaded: MobileNetV3-Large\")\n",
    "    elif model_name == 'EfficientNet-B0':\n",
    "        base_model = keras.applications.EfficientNetB0(\n",
    "            input_shape=(224, 224, 3),\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            # 關鍵：將 base_model 的輸入與我們定義的 `inputs` 張量連接起來\n",
    "            input_tensor=inputs\n",
    "        )\n",
    "        print(\"✅ Base model loaded: EfficientNetB0\")\n",
    "    else:\n",
    "        raise ValueError(f\"不支援的模型名稱: {model_name}。\")\n",
    "        \n",
    "    # --- 設定基底模型的可訓練性 ---\n",
    "    if freeze_base_model:\n",
    "        base_model.trainable = False\n",
    "        print(\"🧊 Base model is FROZEN.\")\n",
    "    else:\n",
    "        base_model.trainable = True\n",
    "        if trainable_layers > 0 and trainable_layers < len(base_model.layers):\n",
    "            # 只解凍尾部的 N 層\n",
    "            for layer in base_model.layers[:-trainable_layers]:\n",
    "                layer.trainable = False\n",
    "            print(f\"🔥 Fine-tuning. Last {trainable_layers} layers of base model are UNFROZEN.\")\n",
    "        else:\n",
    "            # 解凍所有層\n",
    "            print(\"🔥 Fine-tuning. All layers of base model are UNFROZEN.\")\n",
    "\n",
    "    # --- 使用 Functional API 串接模型 ---\n",
    "    # 取得 base_model 的輸出\n",
    "    x = base_model.output\n",
    "    # 連接到後續的層\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(dense_units, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(dense_units, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    # 輸出層\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # 建立最終模型，明確指定輸入和輸出\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 編譯模型\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b38f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MLflow 視覺化與日誌記錄輔助函式 (維持不變)\n",
    "\n",
    "def plot_and_log_history(history, filename=\"history_plots.png\"):\n",
    "    \"\"\"\n",
    "    繪製準確率和損失函數的歷史曲線，並將其儲存為圖片，最後記錄到 MLflow。\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 準確率圖\n",
    "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.set_title('Accuracy over epochs')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # 損失函數圖\n",
    "    ax2.plot(history.history['loss'], label='Train Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Val Loss')\n",
    "    ax2.set_title('Loss over epochs')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # 儲存圖片並關閉繪圖\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)  # 確保關閉正確的 figure\n",
    "    \n",
    "    # 將圖片記錄到 MLflow\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"✅ '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def log_confusion_matrix(y_true, y_pred, class_labels, filename=\"confusion_matrix.png\"):\n",
    "    \"\"\" 繪製、儲存並記錄標準混淆矩陣 \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(18, 14)) # 增加圖片大小以容納更多類別\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels, cmap='Blues')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"✅ '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def plot_and_log_sorted_confusion_bar(y_true, y_pred, class_labels, filename=\"sorted_correct_counts.png\"):\n",
    "    \"\"\" 計算、繪製並記錄一個長條圖，顯示每個類別的正確預測數量（由高到低排序）。 \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    correct_counts = np.diag(cm)\n",
    "    \n",
    "    sorted_idx = np.argsort(correct_counts)[::-1]\n",
    "    sorted_counts = correct_counts[sorted_idx]\n",
    "    sorted_labels = np.array(class_labels)[sorted_idx]\n",
    "\n",
    "    plt.figure(figsize=(18, 8)) # 增加圖片寬度\n",
    "    plt.bar(range(len(sorted_counts)), sorted_counts, color='lightgreen')\n",
    "    plt.xticks(range(len(sorted_labels)), sorted_labels, rotation=90)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Correctly Predicted Count')\n",
    "    plt.title('Correctly Predicted Count per Class (sorted)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_artifact(filename)\n",
    "    print(f\"✅ '{filename}' has been logged to MLflow.\")\n",
    "\n",
    "def evaluate_and_log_all_reports(model, data_generator, class_labels):\n",
    "    \"\"\"\n",
    "    評估模型並記錄分類報告、混淆矩陣及其他分析圖到 MLflow。\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*20 + \" Starting Full Evaluation for Logging \" + \"=\"*20)\n",
    "\n",
    "    # 關鍵：重置 generator 以確保順序正確\n",
    "    data_generator.reset()\n",
    "\n",
    "    # 1. 模型預測\n",
    "    # 使用 predict() 方法，並指定 steps，可以確保處理完所有樣本\n",
    "    predictions = model.predict(data_generator, steps=len(data_generator), verbose=1)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # 2. 取得真實標籤\n",
    "    # 注意：generator 的 classes 屬性包含了所有樣本的真實標籤\n",
    "    y_true = data_generator.classes\n",
    "\n",
    "    # 確保長度一致，這在 generator batch_size 無法整除總樣本數時很重要\n",
    "    if len(y_pred) != len(y_true):\n",
    "        print(f\"⚠️ y_pred length {len(y_pred)} vs y_true length {len(y_true)}. This is normal if batch_size doesn't divide total samples.\")\n",
    "        # `predict` 會處理完所有樣本，所以 y_true 也應該是完整的\n",
    "        y_true = y_true[:len(y_pred)]\n",
    "\n",
    "    # 3. 產生並記錄分類報告\n",
    "    report = classification_report(y_true, y_pred, target_names=class_labels, digits=4, zero_division=0)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    mlflow.log_text(report, \"classification_report.txt\")\n",
    "    print(\"✅ 'classification_report.txt' has been logged to MLflow.\")\n",
    "\n",
    "    # 4. 記錄混淆矩陣\n",
    "    log_confusion_matrix(y_true, y_pred, class_labels)\n",
    "\n",
    "    # 5. 記錄排序後的正確預測數量長條圖\n",
    "    plot_and_log_sorted_confusion_bar(y_true, y_pred, class_labels)\n",
    "    \n",
    "    print(\"=\"*20 + \" Full Evaluation Logging Complete \" + \"=\"*20 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ad3f6",
   "metadata": {},
   "source": [
    "### 兩種模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b30e6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 2. 自動訓練與調參的主函式 (已修改為單階段訓練)\n",
    "def train_and_tune(train_path, validation_path, target_accuracy):\n",
    "    \"\"\"\n",
    "    自動執行單階段的訓練和超參數調整。\n",
    "    為每個模型動態創建使用其專屬 preprocess_input 的數據生成器。\n",
    "    \"\"\"\n",
    "    # 定義超參數的搜尋空間\n",
    "    param_space = {\n",
    "        'model_name': [\n",
    "            'MobileNetV3-Large', \n",
    "            'EfficientNet-B0'],\n",
    "        'learning_rate': [0.001],\n",
    "        'dropout_rate': [0.3],\n",
    "        'dense_units': [256],\n",
    "        'trainable_layers': [80]  # 從頭開始就可訓練的層數\n",
    "    }\n",
    "    \n",
    "    TOTAL_EPOCHS = 1\n",
    "    \n",
    "    keys, values = zip(*param_space.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    best_val_accuracy = 0\n",
    "    best_run_id = None\n",
    "\n",
    "    # 實驗名稱可以更新以反映新的訓練策略\n",
    "    mlflow.set_experiment(\"MobileNetV3 & EfficientNet-B0 單階段訓練(preprocess_input)\")\n",
    "    \n",
    "    for i, params in enumerate(param_combinations):\n",
    "        if best_val_accuracy >= target_accuracy:\n",
    "            print(f\"🎯 目標已達成 (Accuracy >= {target_accuracy:.2f})。停止搜尋。\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"🚀 Run {i+1}/{len(param_combinations)}: 嘗試參數組合: {params}\")\n",
    "\n",
    "        # --- 根據模型名稱選擇預處理函式 (邏輯不變) ---\n",
    "        if params['model_name'] == 'MobileNetV3-Large':\n",
    "            preprocessing_function = mobilenet_v3.preprocess_input\n",
    "            print(\"INFO: Using MobileNetV3 preprocess_input.\")\n",
    "        elif params['model_name'] == 'EfficientNet-B0':\n",
    "            preprocessing_function = efficientnet.preprocess_input\n",
    "            print(\"INFO: Using EfficientNet preprocess_input.\")\n",
    "        else:\n",
    "            raise ValueError(f\"未知的模型: {params['model_name']}\")\n",
    "\n",
    "        # --- 數據生成器 (邏輯不變) ---\n",
    "        train_datagen_aug = ImageDataGenerator(\n",
    "            preprocessing_function=preprocessing_function,\n",
    "            rotation_range=15,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            brightness_range=[0.9, 1.1],\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        validation_datagen = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "        train_gen = train_datagen_aug.flow_from_directory(\n",
    "            train_path, target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=True\n",
    "        )\n",
    "        val_gen = validation_datagen.flow_from_directory(\n",
    "            validation_path, target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=False\n",
    "        )\n",
    "\n",
    "        # 獲取數據集信息與計算 class_weight (邏輯不變)\n",
    "        num_classes = train_gen.num_classes\n",
    "        class_labels = list(train_gen.class_indices.keys())\n",
    "        with open('classes_new.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for cls in class_labels:\n",
    "                writer.writerow([cls])\n",
    "        \n",
    "        class_indices = np.unique(train_gen.classes)\n",
    "        class_weights_array = compute_class_weight(\n",
    "            class_weight='balanced', classes=class_indices, y=train_gen.classes\n",
    "        )\n",
    "        class_weight = dict(zip(class_indices, class_weights_array))\n",
    "\n",
    "        # --- 修改點 2: 合併為單一訓練流程 ---\n",
    "        with mlflow.start_run(run_name=f\"{params['model_name']}_run_{i+1}\") as run:\n",
    "            mlflow.log_params(params)\n",
    "            \n",
    "            print(\"\\n\" + \"-\" * 25 + \" SINGLE STAGE TRAINING \" + \"-\" * 25)\n",
    "\n",
    "            # === 修改點 3: 一次性建構模型進行微調 ===\n",
    "            # 直接設定 freeze_base_model=False，讓模型從一開始就訓練指定的層數\n",
    "            model = build_model(\n",
    "                **params, \n",
    "                num_classes=num_classes, \n",
    "                freeze_base_model=False \n",
    "            )\n",
    "            \n",
    "            # 定義回調函式\n",
    "            callbacks = [\n",
    "                # EarlyStopping 的 patience 可以稍微放寬，因為是單次長時訓練\n",
    "                EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-8),\n",
    "                ModelCheckpoint(\"model_checkpoint.keras\", monitor=\"val_loss\", save_best_only=True)\n",
    "            ]\n",
    "\n",
    "            # === 修改點 4: 執行單次 model.fit ===\n",
    "            history = model.fit(\n",
    "                train_gen, \n",
    "                epochs=TOTAL_EPOCHS,  # 使用合併後的 Epochs\n",
    "                validation_data=val_gen, \n",
    "                callbacks=callbacks, \n",
    "                class_weight=class_weight, \n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # === 修改點 5: MLflow 記錄 (流程簡化) ===\n",
    "            # 直接使用 model.fit 回傳的 history 物件，不需手動合併\n",
    "            val_accuracy = max(history.history['val_accuracy'])\n",
    "            mlflow.log_metric(\"best_val_accuracy\", val_accuracy)\n",
    "            \n",
    "            plot_and_log_history(history) # 直接傳入 history\n",
    "            evaluate_and_log_all_reports(model, val_gen, class_labels)\n",
    "            mlflow.keras.log_model(model, \"model\")\n",
    "            \n",
    "            print(f\"✔️ Run {run.info.run_id} 完成。最佳驗證準確率: {val_accuracy:.4f}\")\n",
    "            \n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                best_run_id = run.info.run_id\n",
    "                print(f\"🎉 新的最佳模型! Model: {params['model_name']}, Run ID: {best_run_id}, Accuracy: {best_val_accuracy:.4f}\")\n",
    "                model.save(f'checkpoints/bestmodel/{i+1}{params['model_name']}_{best_val_accuracy:.4f}.keras')\n",
    "                print(f\"💾 最佳模型已更新並儲存為 '{i+1}{params['model_name']}_{best_val_accuracy:.4f}.keras'\")\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"🏁 自動調參完成。\")\n",
    "    if best_run_id:\n",
    "        print(f\"🏆 最終最佳模型的 Run ID 為: {best_run_id}\")\n",
    "        print(f\"🏆 最終最佳驗證準確率為: {best_val_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(\"❌ 未能成功訓練任何模型。\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e09c9c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 Run 1/2: 嘗試參數組合: {'model_name': 'MobileNetV3-Large', 'learning_rate': 0.001, 'dropout_rate': 0.3, 'dense_units': 256, 'trainable_layers': 80}\n",
      "INFO: Using MobileNetV3 preprocess_input.\n",
      "Found 21859 images belonging to 50 classes.\n",
      "Found 6241 images belonging to 50 classes.\n",
      "\n",
      "------------------------- SINGLE STAGE TRAINING -------------------------\n",
      "✅ Base model loaded: MobileNetV3-Large\n",
      "🔥 Fine-tuning. Last 80 layers of base model are UNFROZEN.\n",
      "\u001b[1m684/684\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1030s\u001b[0m 1s/step - accuracy: 0.6214 - loss: 1.3788 - val_accuracy: 0.3743 - val_loss: 103.9577 - learning_rate: 0.0010\n",
      "✅ 'history_plots.png' has been logged to MLflow.\n",
      "\n",
      "==================== Starting Full Evaluation for Logging ====================\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 443ms/step\n",
      "\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Amaranth     0.8000    0.1301    0.2238       123\n",
      "          Baby Corn     0.7740    0.7584    0.7661       149\n",
      "      Bamboo shoots     0.9375    0.5000    0.6522       120\n",
      "              Basil     0.3846    0.2500    0.3030       120\n",
      "        Beef Tomato     0.2647    0.0750    0.1169       120\n",
      "        Bell pepper     0.9762    0.3417    0.5062       120\n",
      "Big Chinese Cabbage     0.8500    0.5667    0.6800       120\n",
      "       Big cucumber     0.6786    0.1583    0.2568       120\n",
      "           Bok Choy     0.2183    0.2583    0.2366       120\n",
      "    Chinese Cabbage     0.8718    0.2833    0.4277       120\n",
      "       French beans     0.5000    0.2846    0.3627       130\n",
      "             Garlic     0.1125    0.7534    0.1957       146\n",
      "     Green Broccoli     0.8571    0.4865    0.6207       148\n",
      "Green bamboo shoots     0.7222    0.2167    0.3333       120\n",
      "       Green pepper     0.6923    0.3000    0.4186       120\n",
      "               Kale     0.5455    0.4500    0.4932       120\n",
      "            Lettuce     0.7681    0.4417    0.5608       120\n",
      "             Loofah     0.0952    0.9167    0.1725       120\n",
      "         Lotus root     0.4803    0.5083    0.4939       120\n",
      "      Mainland girl     0.4779    0.4500    0.4635       120\n",
      "Momordica charantia     0.3967    0.6083    0.4803       120\n",
      "        Mountain Su     0.7529    0.5333    0.6244       120\n",
      "               Okra     0.6170    0.1388    0.2266       209\n",
      "       Red broccoli     1.0000    0.3417    0.5093       120\n",
      "            Romaine     0.4130    0.7917    0.5429       120\n",
      "           Shallots     0.4082    0.1667    0.2367       120\n",
      "          Sweet Pea     0.2106    0.7583    0.3297       120\n",
      "Sweet potato leaves     0.7500    0.1500    0.2500       120\n",
      "               Taro     0.5192    0.2250    0.3140       120\n",
      "         Water Lily     0.6402    0.8750    0.7394       120\n",
      "      Water spinach     0.1250    0.0080    0.0150       125\n",
      "       Winter melon     0.5082    0.2583    0.3425       120\n",
      "                Yam     0.4667    0.2333    0.3111       120\n",
      "          asparagus     1.0000    0.0643    0.1209       171\n",
      "            brocoli     0.7381    0.5167    0.6078       120\n",
      "            cabbage     0.5859    0.4833    0.5297       120\n",
      "             carrot     0.9101    0.6750    0.7751       120\n",
      "             celery     0.8000    0.1333    0.2286       120\n",
      "              chili     0.7582    0.5750    0.6540       120\n",
      "          coriander     1.0000    0.0750    0.1395       120\n",
      "           eggplant     0.8372    0.3000    0.4417       120\n",
      "             ginger     0.5227    0.1917    0.2805       120\n",
      "        green onion     0.4603    0.4833    0.4715       120\n",
      "              onion     0.1855    0.5333    0.2753       120\n",
      "             potato     0.7121    0.3917    0.5054       120\n",
      "            pumpkin     0.5333    0.2667    0.3556       120\n",
      "               rape     0.3932    0.3833    0.3882       120\n",
      "            spinach     0.7500    0.0250    0.0484       120\n",
      "       sweet potato     0.6522    0.2500    0.3614       120\n",
      "           zucchini     0.3778    0.2833    0.3238       120\n",
      "\n",
      "           accuracy                         0.3743      6241\n",
      "          macro avg     0.6006    0.3770    0.3943      6241\n",
      "       weighted avg     0.6036    0.3743    0.3911      6241\n",
      "\n",
      "✅ 'classification_report.txt' has been logged to MLflow.\n",
      "✅ 'confusion_matrix.png' has been logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:41:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'sorted_correct_counts.png' has been logged to MLflow.\n",
      "==================== Full Evaluation Logging Complete ====================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/18 21:41:02 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/08/18 21:41:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Run d2f17e0671994337b0a23247ce84eaf9 完成。最佳驗證準確率: 0.3743\n",
      "🎉 新的最佳模型! Model: MobileNetV3-Large, Run ID: d2f17e0671994337b0a23247ce84eaf9, Accuracy: 0.3743\n",
      "💾 最佳模型已更新並儲存為 '1MobileNetV3-Large_0.3743.keras'\n",
      "\n",
      "======================================================================\n",
      "🚀 Run 2/2: 嘗試參數組合: {'model_name': 'EfficientNet-B0', 'learning_rate': 0.001, 'dropout_rate': 0.3, 'dense_units': 256, 'trainable_layers': 80}\n",
      "INFO: Using EfficientNet preprocess_input.\n",
      "Found 21859 images belonging to 50 classes.\n",
      "Found 6241 images belonging to 50 classes.\n",
      "\n",
      "------------------------- SINGLE STAGE TRAINING -------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch in layer #1 (named stem_conv)for weight stem_conv/kernel. Weight expects shape (3, 3, 1, 32). Received saved weight with shape (3, 3, 3, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# --- 啟動自動訓練與調參 ---\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# 函式內部會處理數據生成器、類別數量和權重計算\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43mtrain_and_tune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_accuracy\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.98\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36mtrain_and_tune\u001b[39m\u001b[34m(train_path, validation_path, target_accuracy)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m25\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m SINGLE STAGE TRAINING \u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m25\u001b[39m)\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# === 修改點 3: 一次性建構模型進行微調 ===\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# 直接設定 freeze_base_model=False，讓模型從一開始就訓練指定的層數\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m model = \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreeze_base_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# 定義回調函式\u001b[39;00m\n\u001b[32m     96\u001b[39m callbacks = [\n\u001b[32m     97\u001b[39m     \u001b[38;5;66;03m# EarlyStopping 的 patience 可以稍微放寬，因為是單次長時訓練\u001b[39;00m\n\u001b[32m     98\u001b[39m     EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m10\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     99\u001b[39m     ReduceLROnPlateau(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.2\u001b[39m, patience=\u001b[32m3\u001b[39m, min_lr=\u001b[32m1e-8\u001b[39m),\n\u001b[32m    100\u001b[39m     ModelCheckpoint(\u001b[33m\"\u001b[39m\u001b[33mmodel_checkpoint.keras\u001b[39m\u001b[33m\"\u001b[39m, monitor=\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m, save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    101\u001b[39m ]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mbuild_model\u001b[39m\u001b[34m(model_name, learning_rate, dropout_rate, dense_units, trainable_layers, num_classes, freeze_base_model)\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Base model loaded: MobileNetV3-Large\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m model_name == \u001b[33m'\u001b[39m\u001b[33mEfficientNet-B0\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     base_model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapplications\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEfficientNetB0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimagenet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 關鍵：將 base_model 的輸入與我們定義的 `inputs` 張量連接起來\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Base model loaded: EfficientNetB0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cream\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\applications\\efficientnet.py:571\u001b[39m, in \u001b[36mEfficientNetB0\u001b[39m\u001b[34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[39m\n\u001b[32m    555\u001b[39m \u001b[38;5;129m@keras_export\u001b[39m(\n\u001b[32m    556\u001b[39m     [\n\u001b[32m    557\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mkeras.applications.efficientnet.EfficientNetB0\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    569\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mefficientnetb0\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    570\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEfficientNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mb0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cream\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\applications\\efficientnet.py:434\u001b[39m, in \u001b[36mEfficientNet\u001b[39m\u001b[34m(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, weights_name)\u001b[39m\n\u001b[32m    427\u001b[39m     file_name = name + file_suffix\n\u001b[32m    428\u001b[39m     weights_path = file_utils.get_file(\n\u001b[32m    429\u001b[39m         file_name,\n\u001b[32m    430\u001b[39m         BASE_WEIGHTS_PATH + file_name,\n\u001b[32m    431\u001b[39m         cache_subdir=\u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    432\u001b[39m         file_hash=file_hash,\n\u001b[32m    433\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    436\u001b[39m     model.load_weights(weights)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cream\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cream\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:447\u001b[39m, in \u001b[36m_set_weights\u001b[39m\u001b[34m(instance, symbolic_weights, weight_values, name, skip_mismatch)\u001b[39m\n\u001b[32m    437\u001b[39m             warnings.warn(\n\u001b[32m    438\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipping loading weights for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    439\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdue to mismatch in shape for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    444\u001b[39m                 stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    445\u001b[39m             )\n\u001b[32m    446\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    448\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape mismatch in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    449\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor weight \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbolic_weights[i].path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWeight expects shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    451\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mReceived saved weight \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    452\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    453\u001b[39m         )\n\u001b[32m    454\u001b[39m     symbolic_weights[i].assign(weight_value)\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(instance, \u001b[33m\"\u001b[39m\u001b[33mfinalize_state\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m symbolic_weights:\n",
      "\u001b[31mValueError\u001b[39m: Shape mismatch in layer #1 (named stem_conv)for weight stem_conv/kernel. Weight expects shape (3, 3, 1, 32). Received saved weight with shape (3, 3, 3, 32)"
     ]
    }
   ],
   "source": [
    "# --- 定義路徑 ---\n",
    "train_path = \"dataset_full_en_aug3/train\"\n",
    "validation_path = \"dataset_full_en_aug3/validation\"\n",
    "\n",
    "# --- 啟動自動訓練與調參 ---\n",
    "if __name__ == '__main__':\n",
    "    # 函式內部會處理數據生成器、類別數量和權重計算\n",
    "    train_and_tune(\n",
    "        train_path=train_path,\n",
    "        validation_path=validation_path,\n",
    "        target_accuracy=0.98\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
